{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an decoder model which will take in a roundness value and output a pseudoword that corresponds to the roundness value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pseudoword_generator import *\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mepako</td>\n",
       "      <td>0.529904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayo</td>\n",
       "      <td>0.572885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depe</td>\n",
       "      <td>0.505724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nushi</td>\n",
       "      <td>0.588515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poipaau</td>\n",
       "      <td>0.527272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>hipupasago</td>\n",
       "      <td>0.574199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>poniga</td>\n",
       "      <td>0.544438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>pubo</td>\n",
       "      <td>0.555564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>dadapa</td>\n",
       "      <td>0.567358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>nse</td>\n",
       "      <td>0.550246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pseudoword  Roundness\n",
       "0         mepako   0.529904\n",
       "1           bayo   0.572885\n",
       "2           depe   0.505724\n",
       "3          nushi   0.588515\n",
       "4        poipaau   0.527272\n",
       "...          ...        ...\n",
       "9995  hipupasago   0.574199\n",
       "9996      poniga   0.544438\n",
       "9997        pubo   0.555564\n",
       "9998      dadapa   0.567358\n",
       "9999         nse   0.550246\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "\n",
    "data = pd.read_csv(f\"datasets/japanese_pseudowords_{os.getenv(\"VERSION\")}.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.043833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.388763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.571022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.701714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Roundness\n",
       "count  10000.000000\n",
       "mean       0.541609\n",
       "std        0.043833\n",
       "min        0.388763\n",
       "25%        0.510010\n",
       "50%        0.540788\n",
       "75%        0.571022\n",
       "max        0.701714"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, val and test sets\n",
    "\n",
    "trn = data.sample(frac=0.8, random_state=state)\n",
    "val = data.drop(trn.index).sample(frac=0.5, random_state=state)\n",
    "tst = data.drop(trn.index).drop(val.index)\n",
    "trn.reset_index(inplace=True, drop=True)\n",
    "val.reset_index(inplace=True, drop=True)\n",
    "tst.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 8000 samples, Validation set: 1000 samples, Test set: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set: {len(trn)} samples, Validation set: {len(val)} samples, Test set: {len(tst)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model = RoundnessToTextModel(\n",
    "    t5_model_name=\"sonoisa/t5-base-japanese\",\n",
    "    freeze_t5=False,\n",
    "    hidden_dim=256,\n",
    "    output_dim=768,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Train Loss: 9.3923, Validation Loss: 2.6375, Best Val Loss: 2.6375\n",
      "Epoch   2/100, Train Loss: 2.6761, Validation Loss: 2.5136, Best Val Loss: 2.5136\n",
      "Epoch   3/100, Train Loss: 2.5932, Validation Loss: 2.4990, Best Val Loss: 2.4990\n",
      "Epoch   4/100, Train Loss: 2.5511, Validation Loss: 2.4759, Best Val Loss: 2.4759\n",
      "Epoch   5/100, Train Loss: 2.5249, Validation Loss: 2.4664, Best Val Loss: 2.4664\n",
      "Epoch   6/100, Train Loss: 2.5036, Validation Loss: 2.4632, Best Val Loss: 2.4632\n",
      "Epoch   7/100, Train Loss: 2.4761, Validation Loss: 2.4612, Best Val Loss: 2.4612\n",
      "Epoch   8/100, Train Loss: 2.4567, Validation Loss: 2.4643, Best Val Loss: 2.4612\n",
      "Epoch   9/100, Train Loss: 2.4414, Validation Loss: 2.4620, Best Val Loss: 2.4612\n",
      "Epoch  10/100, Train Loss: 2.4144, Validation Loss: 2.4646, Best Val Loss: 2.4612\n",
      "Epoch  11/100, Train Loss: 2.4034, Validation Loss: 2.4724, Best Val Loss: 2.4612\n",
      "Epoch  12/100, Train Loss: 2.3908, Validation Loss: 2.4741, Best Val Loss: 2.4612\n",
      "Epoch  13/100, Train Loss: 2.3715, Validation Loss: 2.4898, Best Val Loss: 2.4612\n",
      "Epoch  14/100, Train Loss: 2.3652, Validation Loss: 2.4967, Best Val Loss: 2.4612\n",
      "Epoch  15/100, Train Loss: 2.3543, Validation Loss: 2.5022, Best Val Loss: 2.4612\n",
      "Epoch  16/100, Train Loss: 2.3420, Validation Loss: 2.5104, Best Val Loss: 2.4612\n",
      "Epoch  17/100, Train Loss: 2.3327, Validation Loss: 2.5182, Best Val Loss: 2.4612\n",
      "Early stopping triggered after 17 epochs\n",
      "Test Loss: 2.5689\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    trn_roundness=trn[\"Roundness\"],\n",
    "    val_roundness=val[\"Roundness\"],\n",
    "    tst_roundness=tst[\"Roundness\"],\n",
    "    trn_texts=trn[\"Pseudoword\"],\n",
    "    val_texts=val[\"Pseudoword\"],\n",
    "    tst_texts=tst[\"Pseudoword\"],\n",
    "    batch_size=min(len(val), 100),\n",
    "    epochs=100,\n",
    "    patience=10,\n",
    "    scheduler=scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roundness Value : 0.534043\n",
      "Original Word   : kira\n",
      "Predicted word  : petsuno\n",
      "\n",
      "Roundness Value : 0.5391055\n",
      "Original Word   : sedagu\n",
      "Predicted word  : ribiroki\n",
      "\n",
      "Roundness Value : 0.5906082\n",
      "Original Word   : mahidazebo\n",
      "Predicted word  : uzufushi\n",
      "\n",
      "Roundness Value : 0.5985307\n",
      "Original Word   : geyaha\n",
      "Predicted word  : higii\n",
      "\n",
      "Roundness Value : 0.51546913\n",
      "Original Word   : shiwaba\n",
      "Predicted word  : shihopizo\n",
      "\n",
      "Roundness Value : 0.58633065\n",
      "Original Word   : ozami\n",
      "Predicted word  : wabui\n",
      "\n",
      "Roundness Value : 0.4962537\n",
      "Original Word   : pekazu\n",
      "Predicted word  : pezoshiga\n",
      "\n",
      "Roundness Value : 0.5527373\n",
      "Original Word   : ige\n",
      "Predicted word  : pimasuzo\n",
      "\n",
      "Roundness Value : 0.59347355\n",
      "Original Word   : boku\n",
      "Predicted word  : mibayo\n",
      "\n",
      "Roundness Value : 0.48744512\n",
      "Original Word   : zuji\n",
      "Predicted word  : yotogega\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_sample = tst.sample(n=10, random_state=42)\n",
    "for _, row in random_sample.iterrows():\n",
    "    print(f\"Roundness Value : {row['Roundness']}\")\n",
    "    print(f\"Original Word   : {row['Pseudoword']}\")\n",
    "    print(f\"Predicted word  : {inference(model, row[\"Roundness\"])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roundness Value: 0.0\n",
      "Predicted word: zeneshi\n",
      "\n",
      "Roundness Value: 0.1\n",
      "Predicted word: nazezaha\n",
      "\n",
      "Roundness Value: 0.2\n",
      "Predicted word: nepatopege\n",
      "\n",
      "Roundness Value: 0.3\n",
      "Predicted word: roketadeta\n",
      "\n",
      "Roundness Value: 0.4\n",
      "Predicted word: kikapete\n",
      "\n",
      "Roundness Value: 0.5\n",
      "Predicted word: bekefume\n",
      "\n",
      "Roundness Value: 0.6\n",
      "Predicted word: dochio\n",
      "\n",
      "Roundness Value: 0.7\n",
      "Predicted word: bogua\n",
      "\n",
      "Roundness Value: 0.8\n",
      "Predicted word: zaho\n",
      "\n",
      "Roundness Value: 0.9\n",
      "Predicted word: maho\n",
      "\n",
      "Roundness Value: 1.0\n",
      "Predicted word: boruu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roundness_list = []\n",
    "for i in range(11):\n",
    "    roundness_list.append(i/10)\n",
    "\n",
    "for roundness in roundness_list:\n",
    "    print(f\"Roundness Value: {roundness}\")\n",
    "    print(f\"Predicted word: {inference(model, roundness)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/pseudoword_generator_v03.1.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model, filename=f\"pseudoword_generator_v0{os.getenv(\"VERSION\")}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(filename=f\"pseudoword_generator_v0{os.getenv(\"VERSION\")}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudoword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
