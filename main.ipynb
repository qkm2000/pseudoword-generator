{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an decoder model which will take in a roundness value and output a pseudoword that corresponds to the roundness value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pseudoword_generator import *\n",
    "from utils.word_tokenizer import *\n",
    "from dotenv import load_dotenv\n",
    "from utils.dataset import *\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bebi</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibe</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bobou</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boubo</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chechi</td>\n",
       "      <td>0.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>outou</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>uku</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ulu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>umu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>utu</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pseudoword  Roundness\n",
       "0         bebi   0.815217\n",
       "1         bibe   0.913043\n",
       "2        bobou   0.815217\n",
       "3        boubo   1.000000\n",
       "4       chechi   0.184783\n",
       "..         ...        ...\n",
       "119      outou   0.347826\n",
       "120        uku   0.239130\n",
       "121        ulu   0.913043\n",
       "122        umu   0.913043\n",
       "123        utu   0.239130\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv(f\"datasets/normalized.csv\")\n",
    "data.rename(columns={\"Stimuli\": \"Pseudoword\", \"ExperimentalRoundScore\": \"Roundness\"}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.316366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Roundness\n",
       "count  124.000000\n",
       "mean     0.562675\n",
       "std      0.316366\n",
       "min      0.000000\n",
       "25%      0.260870\n",
       "50%      0.543478\n",
       "75%      0.902174\n",
       "max      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = trainDataset()\n",
    "val = valDataset()\n",
    "tst = testDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section performs a grid search to determine what are the best parameters to use to train the model. These intermediary models are trained with a smaller number of epochs and a shorter early stopping patience, as we are only looking to see which hyperparameters are the best. Once the best parameters are determined, these parameters will then be taken to train another model with a higher number of epochs and patience to train until the model converges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'd_model': [32, 64, 128],\n",
    "    'nhead': [4, 8],\n",
    "    'num_layers': [4, 8],\n",
    "    'learning_rate': [0.1],\n",
    "    'weight_decay': [0.01, 0.1],\n",
    "    'batch_size': [8],\n",
    "    'max_length': [12, 16]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3078, Average Validation Loss: 3.2076\n",
      "Epoch 2: Average Training Loss: 3.2766, Average Validation Loss: 3.0911\n",
      "Epoch 3: Average Training Loss: 2.8234, Average Validation Loss: 2.5038\n",
      "Epoch 4: Average Training Loss: 2.4685, Average Validation Loss: 2.3828\n",
      "Epoch 5: Average Training Loss: 2.3320, Average Validation Loss: 2.3830\n",
      "Epoch 6: Average Training Loss: 2.2654, Average Validation Loss: 2.2408\n",
      "Epoch 7: Average Training Loss: 2.2038, Average Validation Loss: 2.2492\n",
      "Epoch 8: Average Training Loss: 2.1329, Average Validation Loss: 2.3433\n",
      "Epoch 9: Average Training Loss: 2.0791, Average Validation Loss: 2.1598\n",
      "Epoch 10: Average Training Loss: 2.0263, Average Validation Loss: 2.1434\n",
      "Epoch 11: Average Training Loss: 1.9781, Average Validation Loss: 2.2489\n",
      "Epoch 12: Average Training Loss: 1.9613, Average Validation Loss: 2.1778\n",
      "Epoch 13: Average Training Loss: 1.9001, Average Validation Loss: 2.3535\n",
      "\n",
      "Early stopping triggered after epoch 12\n",
      "Best Validation Loss: 2.1434\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.2716\n",
      "\n",
      "[2/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.2826, Average Validation Loss: 3.3548\n",
      "Epoch 2: Average Training Loss: 3.2362, Average Validation Loss: 3.1921\n",
      "Epoch 3: Average Training Loss: 2.9574, Average Validation Loss: 2.5938\n",
      "Epoch 4: Average Training Loss: 2.5139, Average Validation Loss: 2.2971\n",
      "Epoch 5: Average Training Loss: 2.3607, Average Validation Loss: 2.2927\n",
      "Epoch 6: Average Training Loss: 2.2839, Average Validation Loss: 2.1720\n",
      "Epoch 7: Average Training Loss: 2.2055, Average Validation Loss: 2.4570\n",
      "Epoch 8: Average Training Loss: 2.1138, Average Validation Loss: 2.3626\n",
      "Epoch 9: Average Training Loss: 2.0675, Average Validation Loss: 2.2660\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.1720\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5237\n",
      "\n",
      "[3/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5326, Average Validation Loss: 3.2795\n",
      "Epoch 2: Average Training Loss: 3.4667, Average Validation Loss: 3.0707\n",
      "Epoch 3: Average Training Loss: 2.9925, Average Validation Loss: 2.5021\n",
      "Epoch 4: Average Training Loss: 2.4853, Average Validation Loss: 2.3528\n",
      "Epoch 5: Average Training Loss: 2.3151, Average Validation Loss: 2.4415\n",
      "Epoch 6: Average Training Loss: 2.2664, Average Validation Loss: 2.4473\n",
      "Epoch 7: Average Training Loss: 2.2060, Average Validation Loss: 2.3529\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.3528\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.2864\n",
      "\n",
      "[4/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5198, Average Validation Loss: 3.4809\n",
      "Epoch 2: Average Training Loss: 3.4604, Average Validation Loss: 3.1437\n",
      "Epoch 3: Average Training Loss: 2.9499, Average Validation Loss: 2.6759\n",
      "Epoch 4: Average Training Loss: 2.5678, Average Validation Loss: 2.4820\n",
      "Epoch 5: Average Training Loss: 2.4262, Average Validation Loss: 2.3342\n",
      "Epoch 6: Average Training Loss: 2.3345, Average Validation Loss: 2.3051\n",
      "Epoch 7: Average Training Loss: 2.2679, Average Validation Loss: 2.2736\n",
      "Epoch 8: Average Training Loss: 2.1951, Average Validation Loss: 2.3379\n",
      "Epoch 9: Average Training Loss: 2.1150, Average Validation Loss: 2.3390\n",
      "Epoch 10: Average Training Loss: 2.0557, Average Validation Loss: 2.2399\n",
      "Epoch 11: Average Training Loss: 2.0303, Average Validation Loss: 2.5560\n",
      "Epoch 12: Average Training Loss: 1.9479, Average Validation Loss: 2.3200\n",
      "Epoch 13: Average Training Loss: 1.9079, Average Validation Loss: 2.2468\n",
      "\n",
      "Early stopping triggered after epoch 12\n",
      "Best Validation Loss: 2.2399\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3154\n",
      "\n",
      "[5/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.6347, Average Validation Loss: 3.7021\n",
      "Epoch 2: Average Training Loss: 3.5727, Average Validation Loss: 3.4805\n",
      "Epoch 3: Average Training Loss: 3.2627, Average Validation Loss: 2.7760\n",
      "Epoch 4: Average Training Loss: 2.8074, Average Validation Loss: 2.4673\n",
      "Epoch 5: Average Training Loss: 2.5830, Average Validation Loss: 2.4600\n",
      "Epoch 6: Average Training Loss: 2.4584, Average Validation Loss: 2.4220\n",
      "Epoch 7: Average Training Loss: 2.4236, Average Validation Loss: 2.3691\n",
      "Epoch 8: Average Training Loss: 2.3202, Average Validation Loss: 2.3429\n",
      "Epoch 9: Average Training Loss: 2.3045, Average Validation Loss: 2.5327\n",
      "Epoch 10: Average Training Loss: 2.2940, Average Validation Loss: 2.4808\n",
      "Epoch 11: Average Training Loss: 2.2216, Average Validation Loss: 2.3055\n",
      "Epoch 12: Average Training Loss: 2.1548, Average Validation Loss: 2.3953\n",
      "Epoch 13: Average Training Loss: 2.1381, Average Validation Loss: 2.2262\n",
      "Epoch 14: Average Training Loss: 2.1118, Average Validation Loss: 2.3203\n",
      "Epoch 15: Average Training Loss: 2.0770, Average Validation Loss: 2.3151\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.2538\n",
      "\n",
      "[6/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3497, Average Validation Loss: 3.2844\n",
      "Epoch 2: Average Training Loss: 3.2525, Average Validation Loss: 3.0696\n",
      "Epoch 3: Average Training Loss: 2.9469, Average Validation Loss: 2.7333\n",
      "Epoch 4: Average Training Loss: 2.7310, Average Validation Loss: 2.4622\n",
      "Epoch 5: Average Training Loss: 2.5861, Average Validation Loss: 2.3719\n",
      "Epoch 6: Average Training Loss: 2.4855, Average Validation Loss: 2.2666\n",
      "Epoch 7: Average Training Loss: 2.4312, Average Validation Loss: 2.4381\n",
      "Epoch 8: Average Training Loss: 2.4035, Average Validation Loss: 2.2819\n",
      "Epoch 9: Average Training Loss: 2.3559, Average Validation Loss: 2.4371\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.2666\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3304\n",
      "\n",
      "[7/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4389, Average Validation Loss: 3.4848\n",
      "Epoch 2: Average Training Loss: 3.2387, Average Validation Loss: 2.8780\n",
      "Epoch 3: Average Training Loss: 2.8705, Average Validation Loss: 2.7295\n",
      "Epoch 4: Average Training Loss: 2.6397, Average Validation Loss: 2.6636\n",
      "Epoch 5: Average Training Loss: 2.4467, Average Validation Loss: 2.6754\n",
      "Epoch 6: Average Training Loss: 2.3147, Average Validation Loss: 2.5960\n",
      "Epoch 7: Average Training Loss: 2.2504, Average Validation Loss: 2.4640\n",
      "Epoch 8: Average Training Loss: 2.1870, Average Validation Loss: 2.4002\n",
      "Epoch 9: Average Training Loss: 2.1359, Average Validation Loss: 2.5257\n",
      "Epoch 10: Average Training Loss: 2.1107, Average Validation Loss: 2.4352\n",
      "Epoch 11: Average Training Loss: 2.1228, Average Validation Loss: 2.3143\n",
      "Epoch 12: Average Training Loss: 2.0628, Average Validation Loss: 2.5603\n",
      "Epoch 13: Average Training Loss: 1.9942, Average Validation Loss: 2.3602\n",
      "Epoch 14: Average Training Loss: 1.9835, Average Validation Loss: 2.2874\n",
      "Epoch 15: Average Training Loss: 1.9505, Average Validation Loss: 2.1048\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4359\n",
      "\n",
      "[8/48] Testing parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5711, Average Validation Loss: 3.6711\n",
      "Epoch 2: Average Training Loss: 3.3956, Average Validation Loss: 3.0046\n",
      "Epoch 3: Average Training Loss: 2.9031, Average Validation Loss: 2.6322\n",
      "Epoch 4: Average Training Loss: 2.6081, Average Validation Loss: 2.4420\n",
      "Epoch 5: Average Training Loss: 2.4609, Average Validation Loss: 2.3893\n",
      "Epoch 6: Average Training Loss: 2.3846, Average Validation Loss: 2.2798\n",
      "Epoch 7: Average Training Loss: 2.3397, Average Validation Loss: 2.3927\n",
      "Epoch 8: Average Training Loss: 2.3211, Average Validation Loss: 2.4015\n",
      "Epoch 9: Average Training Loss: 2.2697, Average Validation Loss: 2.4620\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.2798\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5752\n",
      "\n",
      "[9/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4428, Average Validation Loss: 3.4508\n",
      "Epoch 2: Average Training Loss: 3.3421, Average Validation Loss: 3.1722\n",
      "Epoch 3: Average Training Loss: 2.8905, Average Validation Loss: 2.6654\n",
      "Epoch 4: Average Training Loss: 2.5591, Average Validation Loss: 2.5900\n",
      "Epoch 5: Average Training Loss: 2.3954, Average Validation Loss: 2.5619\n",
      "Epoch 6: Average Training Loss: 2.3321, Average Validation Loss: 2.6283\n",
      "Epoch 7: Average Training Loss: 2.2952, Average Validation Loss: 2.5868\n",
      "Epoch 8: Average Training Loss: 2.1913, Average Validation Loss: 2.3069\n",
      "Epoch 9: Average Training Loss: 2.1459, Average Validation Loss: 2.2095\n",
      "Epoch 10: Average Training Loss: 2.0776, Average Validation Loss: 2.3883\n",
      "Epoch 11: Average Training Loss: 2.0131, Average Validation Loss: 2.2321\n",
      "Epoch 12: Average Training Loss: 1.9182, Average Validation Loss: 2.3630\n",
      "\n",
      "Early stopping triggered after epoch 11\n",
      "Best Validation Loss: 2.2095\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.6026\n",
      "\n",
      "[10/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5830, Average Validation Loss: 3.2175\n",
      "Epoch 2: Average Training Loss: 3.5013, Average Validation Loss: 3.0142\n",
      "Epoch 3: Average Training Loss: 3.1377, Average Validation Loss: 2.6547\n",
      "Epoch 4: Average Training Loss: 2.7044, Average Validation Loss: 2.4742\n",
      "Epoch 5: Average Training Loss: 2.4325, Average Validation Loss: 2.5747\n",
      "Epoch 6: Average Training Loss: 2.3054, Average Validation Loss: 2.5206\n",
      "Epoch 7: Average Training Loss: 2.2605, Average Validation Loss: 2.3560\n",
      "Epoch 8: Average Training Loss: 2.2186, Average Validation Loss: 2.3896\n",
      "Epoch 9: Average Training Loss: 2.1678, Average Validation Loss: 2.3568\n",
      "Epoch 10: Average Training Loss: 2.1330, Average Validation Loss: 2.3781\n",
      "\n",
      "Early stopping triggered after epoch 9\n",
      "Best Validation Loss: 2.3560\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.7371\n",
      "\n",
      "[11/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.6452, Average Validation Loss: 3.7002\n",
      "Epoch 2: Average Training Loss: 3.5753, Average Validation Loss: 3.2795\n",
      "Epoch 3: Average Training Loss: 3.0069, Average Validation Loss: 2.7048\n",
      "Epoch 4: Average Training Loss: 2.6297, Average Validation Loss: 2.4199\n",
      "Epoch 5: Average Training Loss: 2.4255, Average Validation Loss: 2.3884\n",
      "Epoch 6: Average Training Loss: 2.3277, Average Validation Loss: 2.4993\n",
      "Epoch 7: Average Training Loss: 2.2628, Average Validation Loss: 2.4725\n",
      "Epoch 8: Average Training Loss: 2.2192, Average Validation Loss: 2.5458\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.3884\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4798\n",
      "\n",
      "[12/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.8100, Average Validation Loss: 3.8699\n",
      "Epoch 2: Average Training Loss: 3.7340, Average Validation Loss: 3.6647\n",
      "Epoch 3: Average Training Loss: 3.1805, Average Validation Loss: 2.6404\n",
      "Epoch 4: Average Training Loss: 2.5729, Average Validation Loss: 2.3621\n",
      "Epoch 5: Average Training Loss: 2.3998, Average Validation Loss: 2.3258\n",
      "Epoch 6: Average Training Loss: 2.3245, Average Validation Loss: 2.3433\n",
      "Epoch 7: Average Training Loss: 2.2534, Average Validation Loss: 2.5749\n",
      "Epoch 8: Average Training Loss: 2.1939, Average Validation Loss: 2.4392\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.3258\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5568\n",
      "\n",
      "[13/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4936, Average Validation Loss: 3.5120\n",
      "Epoch 2: Average Training Loss: 3.4129, Average Validation Loss: 3.1677\n",
      "Epoch 3: Average Training Loss: 2.9441, Average Validation Loss: 2.6042\n",
      "Epoch 4: Average Training Loss: 2.5980, Average Validation Loss: 2.5042\n",
      "Epoch 5: Average Training Loss: 2.4850, Average Validation Loss: 2.4939\n",
      "Epoch 6: Average Training Loss: 2.4168, Average Validation Loss: 2.3915\n",
      "Epoch 7: Average Training Loss: 2.3670, Average Validation Loss: 2.3990\n",
      "Epoch 8: Average Training Loss: 2.3064, Average Validation Loss: 2.3784\n",
      "Epoch 9: Average Training Loss: 2.2644, Average Validation Loss: 2.3218\n",
      "Epoch 10: Average Training Loss: 2.2173, Average Validation Loss: 2.1930\n",
      "Epoch 11: Average Training Loss: 2.1931, Average Validation Loss: 2.2078\n",
      "Epoch 12: Average Training Loss: 2.1351, Average Validation Loss: 2.2057\n",
      "Epoch 13: Average Training Loss: 2.0778, Average Validation Loss: 2.1233\n",
      "Epoch 14: Average Training Loss: 2.0196, Average Validation Loss: 2.1591\n",
      "Epoch 15: Average Training Loss: 2.0185, Average Validation Loss: 2.3282\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.2544\n",
      "\n",
      "[14/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3689, Average Validation Loss: 3.2913\n",
      "Epoch 2: Average Training Loss: 3.2532, Average Validation Loss: 3.0896\n",
      "Epoch 3: Average Training Loss: 2.8663, Average Validation Loss: 2.5733\n",
      "Epoch 4: Average Training Loss: 2.5800, Average Validation Loss: 2.4018\n",
      "Epoch 5: Average Training Loss: 2.4910, Average Validation Loss: 2.3572\n",
      "Epoch 6: Average Training Loss: 2.4159, Average Validation Loss: 2.3072\n",
      "Epoch 7: Average Training Loss: 2.3932, Average Validation Loss: 2.3259\n",
      "Epoch 8: Average Training Loss: 2.3149, Average Validation Loss: 2.4029\n",
      "Epoch 9: Average Training Loss: 2.2576, Average Validation Loss: 2.3145\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.3072\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5278\n",
      "\n",
      "[15/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5259, Average Validation Loss: 3.5693\n",
      "Epoch 2: Average Training Loss: 3.4569, Average Validation Loss: 3.3485\n",
      "Epoch 3: Average Training Loss: 3.1040, Average Validation Loss: 2.6875\n",
      "Epoch 4: Average Training Loss: 2.6984, Average Validation Loss: 2.7344\n",
      "Epoch 5: Average Training Loss: 2.4649, Average Validation Loss: 2.5196\n",
      "Epoch 6: Average Training Loss: 2.4157, Average Validation Loss: 2.6674\n",
      "Epoch 7: Average Training Loss: 2.3565, Average Validation Loss: 2.4513\n",
      "Epoch 8: Average Training Loss: 2.2775, Average Validation Loss: 2.4819\n",
      "Epoch 9: Average Training Loss: 2.2416, Average Validation Loss: 2.3928\n",
      "Epoch 10: Average Training Loss: 2.2013, Average Validation Loss: 2.3562\n",
      "Epoch 11: Average Training Loss: 2.1893, Average Validation Loss: 2.3606\n",
      "Epoch 12: Average Training Loss: 2.1269, Average Validation Loss: 2.3221\n",
      "Epoch 13: Average Training Loss: 2.0899, Average Validation Loss: 2.1132\n",
      "Epoch 14: Average Training Loss: 2.0687, Average Validation Loss: 2.2942\n",
      "Epoch 15: Average Training Loss: 2.0116, Average Validation Loss: 2.0748\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4822\n",
      "\n",
      "[16/48] Testing parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5483, Average Validation Loss: 3.5451\n",
      "Epoch 2: Average Training Loss: 3.3840, Average Validation Loss: 2.9640\n",
      "Epoch 3: Average Training Loss: 2.9314, Average Validation Loss: 2.4901\n",
      "Epoch 4: Average Training Loss: 2.5837, Average Validation Loss: 2.4149\n",
      "Epoch 5: Average Training Loss: 2.4844, Average Validation Loss: 2.3909\n",
      "Epoch 6: Average Training Loss: 2.3885, Average Validation Loss: 2.3677\n",
      "Epoch 7: Average Training Loss: 2.3249, Average Validation Loss: 2.4898\n",
      "Epoch 8: Average Training Loss: 2.3028, Average Validation Loss: 2.2572\n",
      "Epoch 9: Average Training Loss: 2.2344, Average Validation Loss: 2.1746\n",
      "Epoch 10: Average Training Loss: 2.2041, Average Validation Loss: 2.1975\n",
      "Epoch 11: Average Training Loss: 2.1567, Average Validation Loss: 2.3718\n",
      "Epoch 12: Average Training Loss: 2.1176, Average Validation Loss: 2.2166\n",
      "\n",
      "Early stopping triggered after epoch 11\n",
      "Best Validation Loss: 2.1746\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4040\n",
      "\n",
      "[17/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.2704, Average Validation Loss: 3.3450\n",
      "Epoch 2: Average Training Loss: 3.2043, Average Validation Loss: 2.9640\n",
      "Epoch 3: Average Training Loss: 2.7601, Average Validation Loss: 2.5926\n",
      "Epoch 4: Average Training Loss: 2.3374, Average Validation Loss: 2.4266\n",
      "Epoch 5: Average Training Loss: 2.1378, Average Validation Loss: 2.4687\n",
      "Epoch 6: Average Training Loss: 2.0848, Average Validation Loss: 2.3757\n",
      "Epoch 7: Average Training Loss: 2.0420, Average Validation Loss: 2.1533\n",
      "Epoch 8: Average Training Loss: 1.9804, Average Validation Loss: 2.5412\n",
      "Epoch 9: Average Training Loss: 1.9304, Average Validation Loss: 2.2524\n",
      "Epoch 10: Average Training Loss: 1.9095, Average Validation Loss: 2.6983\n",
      "\n",
      "Early stopping triggered after epoch 9\n",
      "Best Validation Loss: 2.1533\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4915\n",
      "\n",
      "[18/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.6550, Average Validation Loss: 3.7256\n",
      "Epoch 2: Average Training Loss: 3.4986, Average Validation Loss: 3.2186\n",
      "Epoch 3: Average Training Loss: 2.8088, Average Validation Loss: 2.4545\n",
      "Epoch 4: Average Training Loss: 2.3685, Average Validation Loss: 2.4374\n",
      "Epoch 5: Average Training Loss: 2.1993, Average Validation Loss: 2.6350\n",
      "Epoch 6: Average Training Loss: 2.1107, Average Validation Loss: 2.2755\n",
      "Epoch 7: Average Training Loss: 2.0260, Average Validation Loss: 2.5926\n",
      "Epoch 8: Average Training Loss: 1.9954, Average Validation Loss: 2.4708\n",
      "Epoch 9: Average Training Loss: 1.9623, Average Validation Loss: 2.3076\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.2755\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4533\n",
      "\n",
      "[19/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3438, Average Validation Loss: 3.4169\n",
      "Epoch 2: Average Training Loss: 3.2487, Average Validation Loss: 3.1193\n",
      "Epoch 3: Average Training Loss: 2.7489, Average Validation Loss: 2.4553\n",
      "Epoch 4: Average Training Loss: 2.3271, Average Validation Loss: 2.5967\n",
      "Epoch 5: Average Training Loss: 2.1428, Average Validation Loss: 2.2504\n",
      "Epoch 6: Average Training Loss: 2.0736, Average Validation Loss: 2.4036\n",
      "Epoch 7: Average Training Loss: 2.0145, Average Validation Loss: 2.3819\n",
      "Epoch 8: Average Training Loss: 1.9917, Average Validation Loss: 2.3409\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.2504\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3983\n",
      "\n",
      "[20/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5424, Average Validation Loss: 3.5085\n",
      "Epoch 2: Average Training Loss: 3.4131, Average Validation Loss: 3.0676\n",
      "Epoch 3: Average Training Loss: 2.7924, Average Validation Loss: 2.3695\n",
      "Epoch 4: Average Training Loss: 2.3363, Average Validation Loss: 2.1942\n",
      "Epoch 5: Average Training Loss: 2.1821, Average Validation Loss: 2.2557\n",
      "Epoch 6: Average Training Loss: 2.1130, Average Validation Loss: 2.2386\n",
      "Epoch 7: Average Training Loss: 2.0628, Average Validation Loss: 2.2150\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.1942\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4236\n",
      "\n",
      "[21/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.6874, Average Validation Loss: 3.7723\n",
      "Epoch 2: Average Training Loss: 3.5072, Average Validation Loss: 3.2120\n",
      "Epoch 3: Average Training Loss: 2.9464, Average Validation Loss: 2.6170\n",
      "Epoch 4: Average Training Loss: 2.5970, Average Validation Loss: 2.4534\n",
      "Epoch 5: Average Training Loss: 2.3997, Average Validation Loss: 2.2874\n",
      "Epoch 6: Average Training Loss: 2.2872, Average Validation Loss: 2.3073\n",
      "Epoch 7: Average Training Loss: 2.2362, Average Validation Loss: 2.2231\n",
      "Epoch 8: Average Training Loss: 2.1595, Average Validation Loss: 2.1872\n",
      "Epoch 9: Average Training Loss: 2.0845, Average Validation Loss: 2.4365\n",
      "Epoch 10: Average Training Loss: 2.0305, Average Validation Loss: 2.2575\n",
      "Epoch 11: Average Training Loss: 2.0084, Average Validation Loss: 2.5342\n",
      "\n",
      "Early stopping triggered after epoch 10\n",
      "Best Validation Loss: 2.1872\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5406\n",
      "\n",
      "[22/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4405, Average Validation Loss: 3.4376\n",
      "Epoch 2: Average Training Loss: 3.3507, Average Validation Loss: 3.0576\n",
      "Epoch 3: Average Training Loss: 2.8644, Average Validation Loss: 2.4253\n",
      "Epoch 4: Average Training Loss: 2.4466, Average Validation Loss: 2.0938\n",
      "Epoch 5: Average Training Loss: 2.2391, Average Validation Loss: 2.2096\n",
      "Epoch 6: Average Training Loss: 2.1635, Average Validation Loss: 2.1128\n",
      "Epoch 7: Average Training Loss: 2.0601, Average Validation Loss: 2.2723\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.0938\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3062\n",
      "\n",
      "[23/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3335, Average Validation Loss: 3.0856\n",
      "Epoch 2: Average Training Loss: 3.1998, Average Validation Loss: 2.7867\n",
      "Epoch 3: Average Training Loss: 2.8070, Average Validation Loss: 2.5888\n",
      "Epoch 4: Average Training Loss: 2.4087, Average Validation Loss: 2.3246\n",
      "Epoch 5: Average Training Loss: 2.1937, Average Validation Loss: 2.5268\n",
      "Epoch 6: Average Training Loss: 2.1114, Average Validation Loss: 2.2264\n",
      "Epoch 7: Average Training Loss: 2.0753, Average Validation Loss: 2.3773\n",
      "Epoch 8: Average Training Loss: 2.0011, Average Validation Loss: 2.1847\n",
      "Epoch 9: Average Training Loss: 1.9789, Average Validation Loss: 2.3683\n",
      "Epoch 10: Average Training Loss: 1.9526, Average Validation Loss: 2.2908\n",
      "Epoch 11: Average Training Loss: 1.9424, Average Validation Loss: 2.4648\n",
      "\n",
      "Early stopping triggered after epoch 10\n",
      "Best Validation Loss: 2.1847\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4092\n",
      "\n",
      "[24/48] Testing parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4201, Average Validation Loss: 3.4836\n",
      "Epoch 2: Average Training Loss: 3.2931, Average Validation Loss: 3.1103\n",
      "Epoch 3: Average Training Loss: 2.8603, Average Validation Loss: 2.5181\n",
      "Epoch 4: Average Training Loss: 2.4685, Average Validation Loss: 2.2584\n",
      "Epoch 5: Average Training Loss: 2.2919, Average Validation Loss: 2.1949\n",
      "Epoch 6: Average Training Loss: 2.1899, Average Validation Loss: 2.3446\n",
      "Epoch 7: Average Training Loss: 2.0978, Average Validation Loss: 2.3064\n",
      "Epoch 8: Average Training Loss: 2.0423, Average Validation Loss: 2.4559\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.1949\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5388\n",
      "\n",
      "[25/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4592, Average Validation Loss: 3.6332\n",
      "Epoch 2: Average Training Loss: 3.4060, Average Validation Loss: 3.1706\n",
      "Epoch 3: Average Training Loss: 2.8616, Average Validation Loss: 2.4345\n",
      "Epoch 4: Average Training Loss: 2.3759, Average Validation Loss: 2.2631\n",
      "Epoch 5: Average Training Loss: 2.2069, Average Validation Loss: 2.3259\n",
      "Epoch 6: Average Training Loss: 2.1294, Average Validation Loss: 2.2103\n",
      "Epoch 7: Average Training Loss: 2.0503, Average Validation Loss: 2.2793\n",
      "Epoch 8: Average Training Loss: 1.9743, Average Validation Loss: 2.3595\n",
      "Epoch 9: Average Training Loss: 1.9473, Average Validation Loss: 2.3134\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.2103\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3944\n",
      "\n",
      "[26/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3064, Average Validation Loss: 3.4509\n",
      "Epoch 2: Average Training Loss: 3.2155, Average Validation Loss: 3.1489\n",
      "Epoch 3: Average Training Loss: 2.8031, Average Validation Loss: 2.5868\n",
      "Epoch 4: Average Training Loss: 2.3266, Average Validation Loss: 2.2992\n",
      "Epoch 5: Average Training Loss: 2.1582, Average Validation Loss: 2.4579\n",
      "Epoch 6: Average Training Loss: 2.1010, Average Validation Loss: 2.2394\n",
      "Epoch 7: Average Training Loss: 2.0396, Average Validation Loss: 2.5715\n",
      "Epoch 8: Average Training Loss: 1.9924, Average Validation Loss: 2.1749\n",
      "Epoch 9: Average Training Loss: 1.9510, Average Validation Loss: 2.5869\n",
      "Epoch 10: Average Training Loss: 1.9274, Average Validation Loss: 2.4593\n",
      "Epoch 11: Average Training Loss: 1.8823, Average Validation Loss: 2.3812\n",
      "\n",
      "Early stopping triggered after epoch 10\n",
      "Best Validation Loss: 2.1749\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4697\n",
      "\n",
      "[27/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4581, Average Validation Loss: 3.6870\n",
      "Epoch 2: Average Training Loss: 3.3116, Average Validation Loss: 3.0049\n",
      "Epoch 3: Average Training Loss: 2.6751, Average Validation Loss: 2.2881\n",
      "Epoch 4: Average Training Loss: 2.2913, Average Validation Loss: 2.2848\n",
      "Epoch 5: Average Training Loss: 2.1509, Average Validation Loss: 2.1979\n",
      "Epoch 6: Average Training Loss: 2.0889, Average Validation Loss: 2.4529\n",
      "Epoch 7: Average Training Loss: 2.0327, Average Validation Loss: 2.4451\n",
      "Epoch 8: Average Training Loss: 2.0199, Average Validation Loss: 2.3870\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.1979\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5369\n",
      "\n",
      "[28/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3965, Average Validation Loss: 3.4882\n",
      "Epoch 2: Average Training Loss: 3.2907, Average Validation Loss: 2.9900\n",
      "Epoch 3: Average Training Loss: 2.7853, Average Validation Loss: 2.3869\n",
      "Epoch 4: Average Training Loss: 2.3363, Average Validation Loss: 2.3225\n",
      "Epoch 5: Average Training Loss: 2.1496, Average Validation Loss: 2.3415\n",
      "Epoch 6: Average Training Loss: 2.0616, Average Validation Loss: 2.2382\n",
      "Epoch 7: Average Training Loss: 2.0095, Average Validation Loss: 2.2898\n",
      "Epoch 8: Average Training Loss: 1.9585, Average Validation Loss: 2.2767\n",
      "Epoch 9: Average Training Loss: 1.9065, Average Validation Loss: 2.2703\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.2382\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3626\n",
      "\n",
      "[29/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5751, Average Validation Loss: 3.5559\n",
      "Epoch 2: Average Training Loss: 3.3889, Average Validation Loss: 3.0466\n",
      "Epoch 3: Average Training Loss: 2.7491, Average Validation Loss: 2.3442\n",
      "Epoch 4: Average Training Loss: 2.3511, Average Validation Loss: 2.1673\n",
      "Epoch 5: Average Training Loss: 2.2318, Average Validation Loss: 2.1537\n",
      "Epoch 6: Average Training Loss: 2.1615, Average Validation Loss: 2.1211\n",
      "Epoch 7: Average Training Loss: 2.1112, Average Validation Loss: 2.2831\n",
      "Epoch 8: Average Training Loss: 2.0622, Average Validation Loss: 2.1699\n",
      "Epoch 9: Average Training Loss: 2.0375, Average Validation Loss: 2.3843\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.1211\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5434\n",
      "\n",
      "[30/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4271, Average Validation Loss: 3.3936\n",
      "Epoch 2: Average Training Loss: 3.2747, Average Validation Loss: 2.9266\n",
      "Epoch 3: Average Training Loss: 2.8382, Average Validation Loss: 2.4023\n",
      "Epoch 4: Average Training Loss: 2.4540, Average Validation Loss: 2.2406\n",
      "Epoch 5: Average Training Loss: 2.2983, Average Validation Loss: 2.2732\n",
      "Epoch 6: Average Training Loss: 2.1724, Average Validation Loss: 2.3108\n",
      "Epoch 7: Average Training Loss: 2.0841, Average Validation Loss: 2.3976\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.2406\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3101\n",
      "\n",
      "[31/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3447, Average Validation Loss: 3.2467\n",
      "Epoch 2: Average Training Loss: 3.2411, Average Validation Loss: 2.9747\n",
      "Epoch 3: Average Training Loss: 2.8490, Average Validation Loss: 2.6340\n",
      "Epoch 4: Average Training Loss: 2.5238, Average Validation Loss: 2.3701\n",
      "Epoch 5: Average Training Loss: 2.3023, Average Validation Loss: 2.1838\n",
      "Epoch 6: Average Training Loss: 2.1837, Average Validation Loss: 2.1729\n",
      "Epoch 7: Average Training Loss: 2.1270, Average Validation Loss: 2.1505\n",
      "Epoch 8: Average Training Loss: 2.0866, Average Validation Loss: 2.2182\n",
      "Epoch 9: Average Training Loss: 2.0218, Average Validation Loss: 2.2157\n",
      "Epoch 10: Average Training Loss: 2.0072, Average Validation Loss: 2.0279\n",
      "Epoch 11: Average Training Loss: 1.9863, Average Validation Loss: 2.1562\n",
      "Epoch 12: Average Training Loss: 1.9581, Average Validation Loss: 2.2333\n",
      "Epoch 13: Average Training Loss: 1.9305, Average Validation Loss: 2.4396\n",
      "\n",
      "Early stopping triggered after epoch 12\n",
      "Best Validation Loss: 2.0279\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5653\n",
      "\n",
      "[32/48] Testing parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5749, Average Validation Loss: 3.5668\n",
      "Epoch 2: Average Training Loss: 3.4681, Average Validation Loss: 3.1489\n",
      "Epoch 3: Average Training Loss: 2.9505, Average Validation Loss: 2.4909\n",
      "Epoch 4: Average Training Loss: 2.4477, Average Validation Loss: 2.2255\n",
      "Epoch 5: Average Training Loss: 2.2516, Average Validation Loss: 2.3003\n",
      "Epoch 6: Average Training Loss: 2.1746, Average Validation Loss: 2.1889\n",
      "Epoch 7: Average Training Loss: 2.1110, Average Validation Loss: 2.3766\n",
      "Epoch 8: Average Training Loss: 2.0440, Average Validation Loss: 2.3239\n",
      "Epoch 9: Average Training Loss: 2.0349, Average Validation Loss: 2.2006\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.1889\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4545\n",
      "\n",
      "[33/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4483, Average Validation Loss: 3.2836\n",
      "Epoch 2: Average Training Loss: 3.2431, Average Validation Loss: 2.7091\n",
      "Epoch 3: Average Training Loss: 2.3915, Average Validation Loss: 2.1634\n",
      "Epoch 4: Average Training Loss: 2.0913, Average Validation Loss: 2.2082\n",
      "Epoch 5: Average Training Loss: 1.9760, Average Validation Loss: 2.4248\n",
      "Epoch 6: Average Training Loss: 1.9264, Average Validation Loss: 2.2706\n",
      "\n",
      "Early stopping triggered after epoch 5\n",
      "Best Validation Loss: 2.1634\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4201\n",
      "\n",
      "[34/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5447, Average Validation Loss: 3.4073\n",
      "Epoch 2: Average Training Loss: 3.3255, Average Validation Loss: 2.8933\n",
      "Epoch 3: Average Training Loss: 2.6166, Average Validation Loss: 2.1866\n",
      "Epoch 4: Average Training Loss: 2.1722, Average Validation Loss: 2.1824\n",
      "Epoch 5: Average Training Loss: 2.0178, Average Validation Loss: 2.2349\n",
      "Epoch 6: Average Training Loss: 1.9845, Average Validation Loss: 2.2699\n",
      "Epoch 7: Average Training Loss: 1.8971, Average Validation Loss: 2.2998\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.1824\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3851\n",
      "\n",
      "[35/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.6105, Average Validation Loss: 3.9000\n",
      "Epoch 2: Average Training Loss: 3.4458, Average Validation Loss: 3.0776\n",
      "Epoch 3: Average Training Loss: 2.5675, Average Validation Loss: 2.1999\n",
      "Epoch 4: Average Training Loss: 2.1488, Average Validation Loss: 2.0990\n",
      "Epoch 5: Average Training Loss: 1.9899, Average Validation Loss: 2.4662\n",
      "Epoch 6: Average Training Loss: 1.9444, Average Validation Loss: 2.4695\n",
      "Epoch 7: Average Training Loss: 1.8928, Average Validation Loss: 2.2107\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.0990\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4161\n",
      "\n",
      "[36/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4398, Average Validation Loss: 3.3408\n",
      "Epoch 2: Average Training Loss: 3.3266, Average Validation Loss: 2.8755\n",
      "Epoch 3: Average Training Loss: 2.6078, Average Validation Loss: 2.2077\n",
      "Epoch 4: Average Training Loss: 2.1396, Average Validation Loss: 2.1690\n",
      "Epoch 5: Average Training Loss: 1.9963, Average Validation Loss: 2.2561\n",
      "Epoch 6: Average Training Loss: 1.9403, Average Validation Loss: 2.2357\n",
      "Epoch 7: Average Training Loss: 1.9294, Average Validation Loss: 2.1345\n",
      "Epoch 8: Average Training Loss: 1.8721, Average Validation Loss: 2.4908\n",
      "Epoch 9: Average Training Loss: 1.8696, Average Validation Loss: 2.4780\n",
      "Epoch 10: Average Training Loss: 1.8396, Average Validation Loss: 2.2469\n",
      "\n",
      "Early stopping triggered after epoch 9\n",
      "Best Validation Loss: 2.1345\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3455\n",
      "\n",
      "[37/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4229, Average Validation Loss: 3.4430\n",
      "Epoch 2: Average Training Loss: 3.2602, Average Validation Loss: 3.0163\n",
      "Epoch 3: Average Training Loss: 2.6137, Average Validation Loss: 2.3126\n",
      "Epoch 4: Average Training Loss: 2.1750, Average Validation Loss: 2.2404\n",
      "Epoch 5: Average Training Loss: 2.0453, Average Validation Loss: 2.2637\n",
      "Epoch 6: Average Training Loss: 1.9859, Average Validation Loss: 2.3291\n",
      "Epoch 7: Average Training Loss: 1.8995, Average Validation Loss: 2.4718\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.2404\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.6277\n",
      "\n",
      "[38/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3677, Average Validation Loss: 3.2431\n",
      "Epoch 2: Average Training Loss: 3.2002, Average Validation Loss: 2.7564\n",
      "Epoch 3: Average Training Loss: 2.6270, Average Validation Loss: 2.2496\n",
      "Epoch 4: Average Training Loss: 2.2778, Average Validation Loss: 2.1900\n",
      "Epoch 5: Average Training Loss: 2.1033, Average Validation Loss: 2.2199\n",
      "Epoch 6: Average Training Loss: 2.0437, Average Validation Loss: 2.1175\n",
      "Epoch 7: Average Training Loss: 1.9513, Average Validation Loss: 2.3461\n",
      "Epoch 8: Average Training Loss: 1.9160, Average Validation Loss: 2.3092\n",
      "Epoch 9: Average Training Loss: 1.8979, Average Validation Loss: 2.0902\n",
      "Epoch 10: Average Training Loss: 1.8685, Average Validation Loss: 2.5529\n",
      "Epoch 11: Average Training Loss: 1.8322, Average Validation Loss: 2.1945\n",
      "Epoch 12: Average Training Loss: 1.8385, Average Validation Loss: 2.2210\n",
      "\n",
      "Early stopping triggered after epoch 11\n",
      "Best Validation Loss: 2.0902\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4585\n",
      "\n",
      "[39/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3730, Average Validation Loss: 3.3276\n",
      "Epoch 2: Average Training Loss: 3.2151, Average Validation Loss: 2.8052\n",
      "Epoch 3: Average Training Loss: 2.5913, Average Validation Loss: 2.1133\n",
      "Epoch 4: Average Training Loss: 2.2015, Average Validation Loss: 2.0496\n",
      "Epoch 5: Average Training Loss: 2.0568, Average Validation Loss: 2.3183\n",
      "Epoch 6: Average Training Loss: 1.9901, Average Validation Loss: 2.2960\n",
      "Epoch 7: Average Training Loss: 1.9307, Average Validation Loss: 2.0762\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.0496\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3894\n",
      "\n",
      "[40/48] Testing parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.2901, Average Validation Loss: 3.1672\n",
      "Epoch 2: Average Training Loss: 3.1190, Average Validation Loss: 2.8144\n",
      "Epoch 3: Average Training Loss: 2.6533, Average Validation Loss: 2.2642\n",
      "Epoch 4: Average Training Loss: 2.2716, Average Validation Loss: 2.1318\n",
      "Epoch 5: Average Training Loss: 2.1215, Average Validation Loss: 2.1156\n",
      "Epoch 6: Average Training Loss: 2.0071, Average Validation Loss: 2.1062\n",
      "Epoch 7: Average Training Loss: 1.9381, Average Validation Loss: 2.1146\n",
      "Epoch 8: Average Training Loss: 1.8868, Average Validation Loss: 2.3514\n",
      "Epoch 9: Average Training Loss: 1.8680, Average Validation Loss: 2.2115\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.1062\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4441\n",
      "\n",
      "[41/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5918, Average Validation Loss: 3.7770\n",
      "Epoch 2: Average Training Loss: 3.4155, Average Validation Loss: 2.9367\n",
      "Epoch 3: Average Training Loss: 2.5370, Average Validation Loss: 2.1310\n",
      "Epoch 4: Average Training Loss: 2.1362, Average Validation Loss: 2.1067\n",
      "Epoch 5: Average Training Loss: 2.0161, Average Validation Loss: 2.2045\n",
      "Epoch 6: Average Training Loss: 1.9556, Average Validation Loss: 2.0741\n",
      "Epoch 7: Average Training Loss: 1.9185, Average Validation Loss: 2.1333\n",
      "Epoch 8: Average Training Loss: 1.8903, Average Validation Loss: 2.1678\n",
      "Epoch 9: Average Training Loss: 1.8484, Average Validation Loss: 2.1446\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.0741\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.5128\n",
      "\n",
      "[42/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.7419, Average Validation Loss: 3.6051\n",
      "Epoch 2: Average Training Loss: 3.5833, Average Validation Loss: 3.0170\n",
      "Epoch 3: Average Training Loss: 2.6600, Average Validation Loss: 2.1412\n",
      "Epoch 4: Average Training Loss: 2.1694, Average Validation Loss: 2.1395\n",
      "Epoch 5: Average Training Loss: 2.0543, Average Validation Loss: 2.3100\n",
      "Epoch 6: Average Training Loss: 1.9755, Average Validation Loss: 2.2269\n",
      "Epoch 7: Average Training Loss: 1.9137, Average Validation Loss: 2.2177\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.1395\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4176\n",
      "\n",
      "[43/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.3487, Average Validation Loss: 3.1725\n",
      "Epoch 2: Average Training Loss: 3.1935, Average Validation Loss: 2.8199\n",
      "Epoch 3: Average Training Loss: 2.5658, Average Validation Loss: 2.2876\n",
      "Epoch 4: Average Training Loss: 2.1529, Average Validation Loss: 2.1527\n",
      "Epoch 5: Average Training Loss: 1.9868, Average Validation Loss: 2.1529\n",
      "Epoch 6: Average Training Loss: 1.9346, Average Validation Loss: 2.3413\n",
      "Epoch 7: Average Training Loss: 1.8758, Average Validation Loss: 2.2082\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.1527\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4498\n",
      "\n",
      "[44/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4130, Average Validation Loss: 3.3874\n",
      "Epoch 2: Average Training Loss: 3.2403, Average Validation Loss: 2.9361\n",
      "Epoch 3: Average Training Loss: 2.6512, Average Validation Loss: 2.1690\n",
      "Epoch 4: Average Training Loss: 2.1921, Average Validation Loss: 2.2708\n",
      "Epoch 5: Average Training Loss: 2.0269, Average Validation Loss: 2.1032\n",
      "Epoch 6: Average Training Loss: 1.9508, Average Validation Loss: 2.0151\n",
      "Epoch 7: Average Training Loss: 1.8864, Average Validation Loss: 2.1899\n",
      "Epoch 8: Average Training Loss: 1.8272, Average Validation Loss: 2.2830\n",
      "Epoch 9: Average Training Loss: 1.7928, Average Validation Loss: 2.4670\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.0151\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4780\n",
      "\n",
      "[45/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.5657, Average Validation Loss: 3.4844\n",
      "Epoch 2: Average Training Loss: 3.3036, Average Validation Loss: 2.8096\n",
      "Epoch 3: Average Training Loss: 2.6922, Average Validation Loss: 2.2500\n",
      "Epoch 4: Average Training Loss: 2.3009, Average Validation Loss: 2.0646\n",
      "Epoch 5: Average Training Loss: 2.1217, Average Validation Loss: 2.0934\n",
      "Epoch 6: Average Training Loss: 1.9977, Average Validation Loss: 2.1282\n",
      "Epoch 7: Average Training Loss: 1.9442, Average Validation Loss: 2.1319\n",
      "\n",
      "Early stopping triggered after epoch 6\n",
      "Best Validation Loss: 2.0646\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4860\n",
      "\n",
      "[46/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.7247, Average Validation Loss: 3.6631\n",
      "Epoch 2: Average Training Loss: 3.4016, Average Validation Loss: 2.7658\n",
      "Epoch 3: Average Training Loss: 2.5889, Average Validation Loss: 2.2179\n",
      "Epoch 4: Average Training Loss: 2.2235, Average Validation Loss: 2.0761\n",
      "Epoch 5: Average Training Loss: 2.1050, Average Validation Loss: 2.0720\n",
      "Epoch 6: Average Training Loss: 2.0217, Average Validation Loss: 1.9762\n",
      "Epoch 7: Average Training Loss: 1.9528, Average Validation Loss: 2.2898\n",
      "Epoch 8: Average Training Loss: 1.9013, Average Validation Loss: 2.3518\n",
      "Epoch 9: Average Training Loss: 1.8648, Average Validation Loss: 2.2791\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 1.9762\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4070\n",
      "\n",
      "[47/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 12}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4858, Average Validation Loss: 3.4583\n",
      "Epoch 2: Average Training Loss: 3.2078, Average Validation Loss: 2.8762\n",
      "Epoch 3: Average Training Loss: 2.5682, Average Validation Loss: 2.1839\n",
      "Epoch 4: Average Training Loss: 2.2407, Average Validation Loss: 2.2194\n",
      "Epoch 5: Average Training Loss: 2.1106, Average Validation Loss: 2.0566\n",
      "Epoch 6: Average Training Loss: 2.0117, Average Validation Loss: 2.2556\n",
      "Epoch 7: Average Training Loss: 1.9581, Average Validation Loss: 2.2747\n",
      "Epoch 8: Average Training Loss: 1.9237, Average Validation Loss: 2.1162\n",
      "\n",
      "Early stopping triggered after epoch 7\n",
      "Best Validation Loss: 2.0566\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.3519\n",
      "\n",
      "[48/48] Testing parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.1, 'batch_size': 8, 'max_length': 16}\n",
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.2927, Average Validation Loss: 3.3163\n",
      "Epoch 2: Average Training Loss: 3.1124, Average Validation Loss: 3.0367\n",
      "Epoch 3: Average Training Loss: 2.7090, Average Validation Loss: 2.4057\n",
      "Epoch 4: Average Training Loss: 2.3291, Average Validation Loss: 2.1742\n",
      "Epoch 5: Average Training Loss: 2.1543, Average Validation Loss: 2.3419\n",
      "Epoch 6: Average Training Loss: 2.0880, Average Validation Loss: 2.0764\n",
      "Epoch 7: Average Training Loss: 2.0141, Average Validation Loss: 2.0992\n",
      "Epoch 8: Average Training Loss: 1.9601, Average Validation Loss: 2.1026\n",
      "Epoch 9: Average Training Loss: 1.9162, Average Validation Loss: 2.3976\n",
      "\n",
      "Early stopping triggered after epoch 8\n",
      "Best Validation Loss: 2.0764\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4868\n",
      "\n",
      "Grid search completed!\n",
      "Best parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 8, 'learning_rate': 0.1, 'weight_decay': 0.01, 'batch_size': 8, 'max_length': 16}\n",
      "Best validation loss: 1.9761894345283508\n"
     ]
    }
   ],
   "source": [
    "result = grid_search(\n",
    "    trn=trn,\n",
    "    val=val,\n",
    "    tst=tst,\n",
    "    param_grid=param_grid,\n",
    "    epochs=15,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using decoupled weight decay\n",
      "Epoch 1: Average Training Loss: 3.4873, Average Validation Loss: 3.3733\n",
      "Epoch 2: Average Training Loss: 3.1850, Average Validation Loss: 2.6892\n",
      "Epoch 3: Average Training Loss: 2.6327, Average Validation Loss: 2.1683\n",
      "Epoch 4: Average Training Loss: 2.2704, Average Validation Loss: 2.1586\n",
      "Epoch 5: Average Training Loss: 2.1139, Average Validation Loss: 1.9989\n",
      "Epoch 6: Average Training Loss: 2.0129, Average Validation Loss: 2.0594\n",
      "Epoch 7: Average Training Loss: 1.9254, Average Validation Loss: 2.2337\n",
      "Epoch 8: Average Training Loss: 1.9074, Average Validation Loss: 2.0872\n",
      "Epoch 9: Average Training Loss: 1.8534, Average Validation Loss: 2.1617\n",
      "Epoch 10: Average Training Loss: 1.8616, Average Validation Loss: 2.1720\n",
      "Epoch 11: Average Training Loss: 1.8451, Average Validation Loss: 2.3368\n",
      "Epoch 12: Average Training Loss: 1.8268, Average Validation Loss: 2.1504\n",
      "Epoch 13: Average Training Loss: 1.8280, Average Validation Loss: 2.2554\n",
      "Epoch 14: Average Training Loss: 1.8137, Average Validation Loss: 2.4891\n",
      "Epoch 15: Average Training Loss: 1.7873, Average Validation Loss: 2.2837\n",
      "\n",
      "Early stopping triggered after epoch 14\n",
      "Best Validation Loss: 1.9989\n",
      "\n",
      "Evaluating on test set...\n",
      "Final Test Results:\n",
      "Average Test Loss: 2.4039\n"
     ]
    }
   ],
   "source": [
    "train_result = train(trn, val, tst, params=result[\"parameters\"], epochs=100, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_val_loss': 1.9988694787025452,\n",
       " 'final_test_loss': 2.4038931131362915,\n",
       " 'model': WordTransformer(\n",
       "   (input_embed): Sequential(\n",
       "     (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "   )\n",
       "   (token_embed): Embedding(29, 128)\n",
       "   (transformer_decoder): TransformerDecoder(\n",
       "     (layers): ModuleList(\n",
       "       (0-7): 8 x TransformerDecoderLayer(\n",
       "         (self_attn): MultiheadAttention(\n",
       "           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "         )\n",
       "         (multihead_attn): MultiheadAttention(\n",
       "           (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "         )\n",
       "         (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "         (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "         (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "         (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "         (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "         (dropout3): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (output_proj): Linear(in_features=128, out_features=29, bias=True)\n",
       " ),\n",
       " 'tokenizer': <utils.word_tokenizer.wordTokenizer at 0x1fd9a4f6fc0>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roundness Value : 0.4565217391304347\n",
      "Original Word   : guegui\n",
      "Predicted word  : toui\n",
      "\n",
      "Roundness Value : 0.3695652173913043\n",
      "Original Word   : sise\n",
      "Predicted word  : toui\n",
      "\n",
      "Roundness Value : 0.9130434782608696\n",
      "Original Word   : nonou\n",
      "Predicted word  : louoo\n",
      "\n",
      "Roundness Value : 0.8695652173913043\n",
      "Original Word   : minlin\n",
      "Predicted word  : louoo\n",
      "\n",
      "Roundness Value : 0.0\n",
      "Original Word   : zize\n",
      "Predicted word  : keke\n",
      "\n",
      "Roundness Value : 0.8695652173913043\n",
      "Original Word   : ama\n",
      "Predicted word  : louoo\n",
      "\n",
      "Roundness Value : 0.3695652173913043\n",
      "Original Word   : kantan\n",
      "Predicted word  : toui\n",
      "\n",
      "Roundness Value : 0.9130434782608696\n",
      "Original Word   : umu\n",
      "Predicted word  : louoo\n",
      "\n",
      "Roundness Value : 0.9130434782608696\n",
      "Original Word   : ulu\n",
      "Predicted word  : louoo\n",
      "\n",
      "Roundness Value : 0.1847826086956521\n",
      "Original Word   : chechi\n",
      "Predicted word  : kiui\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_sample = data.sample(n=10, random_state=42)\n",
    "for _, row in random_sample.iterrows():\n",
    "    print(f\"Roundness Value : {row['Roundness']}\")\n",
    "    print(f\"Original Word   : {row['Pseudoword']}\")\n",
    "    print(f\"Predicted word  : {inference(train_result['model'], row['Roundness'], train_result['tokenizer'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roundness Value: 0.0\n",
      "Predicted word: keke\n",
      "\n",
      "Roundness Value: 0.1\n",
      "Predicted word: keki\n",
      "\n",
      "Roundness Value: 0.2\n",
      "Predicted word: tiui\n",
      "\n",
      "Roundness Value: 0.3\n",
      "Predicted word: toui\n",
      "\n",
      "Roundness Value: 0.4\n",
      "Predicted word: toui\n",
      "\n",
      "Roundness Value: 0.5\n",
      "Predicted word: toui\n",
      "\n",
      "Roundness Value: 0.6\n",
      "Predicted word: louo\n",
      "\n",
      "Roundness Value: 0.7\n",
      "Predicted word: louo\n",
      "\n",
      "Roundness Value: 0.8\n",
      "Predicted word: louoo\n",
      "\n",
      "Roundness Value: 0.9\n",
      "Predicted word: louoo\n",
      "\n",
      "Roundness Value: 1.0\n",
      "Predicted word: louoo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roundness_list = []\n",
    "for i in range(11):\n",
    "    roundness_list.append(i/10)\n",
    "\n",
    "for roundness in roundness_list:\n",
    "    print(f\"Roundness Value: {roundness}\")\n",
    "    print(f\"Predicted word: {inference(train_result['model'], roundness, train_result['tokenizer'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(train_result['model'], path=f\"outputs/pseudoword_generator_v0{os.getenv(\"GEN\")}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"outputs/params_for_model_v0{os.getenv(\"GEN\")}.json\", \"w\") as f:\n",
    "    json.dump(result[\"parameters\"], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(filename=f\"pseudoword_generator_v0{os.getenv(\"GEN\")}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudoword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
