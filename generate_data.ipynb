{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to generate more data for the main model to use.\n",
    "\n",
    "This model is trained on (normalized.csv) to be able to predict the roundness of pseudowords.\n",
    "\n",
    "This is because the original dataset (normalized.csv) only contains 124 rows, and it is insufficient to train a large model like the ByT5-Pseudword-Generator. Hence, this model should learn to predict the roundness values of pseudowords, then be applied on a larger dataset to create a dataset of pseudoword-roundness pairs that will be used to train the ByT5-Pseudword-Generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qkm20\\anaconda3\\envs\\pseudoword\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.roundness_determiner import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "\n",
    "\n",
    "state = 42\n",
    "VERSION = 3\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stimuli</th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bebi</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibe</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bobou</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boubo</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chechi</td>\n",
       "      <td>0.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>outou</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>uku</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ulu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>umu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>utu</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stimuli  ExperimentalRoundScore\n",
       "0      bebi                0.815217\n",
       "1      bibe                0.913043\n",
       "2     bobou                0.815217\n",
       "3     boubo                1.000000\n",
       "4    chechi                0.184783\n",
       "..      ...                     ...\n",
       "119   outou                0.347826\n",
       "120     uku                0.239130\n",
       "121     ulu                0.913043\n",
       "122     umu                0.913043\n",
       "123     utu                0.239130\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/normalized.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.316366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ExperimentalRoundScore\n",
       "count              124.000000\n",
       "mean                 0.562675\n",
       "std                  0.316366\n",
       "min                  0.000000\n",
       "25%                  0.260870\n",
       "50%                  0.543478\n",
       "75%                  0.902174\n",
       "max                  1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = roundness_determiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/12\n",
      "Epoch    1/1000 | Train Loss: 0.8974 | Val Loss: 0.7281 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.8088 | Val Loss: 0.7142 | Best Val: 0.7281\n",
      "Epoch    3/1000 | Train Loss: 0.7531 | Val Loss: 0.7030 | Best Val: 0.7142\n",
      "Epoch    4/1000 | Train Loss: 0.7170 | Val Loss: 0.6768 | Best Val: 0.7030\n",
      "Epoch    5/1000 | Train Loss: 0.6966 | Val Loss: 0.6566 | Best Val: 0.6768\n",
      "Epoch    6/1000 | Train Loss: 0.6795 | Val Loss: 0.6538 | Best Val: 0.6566\n",
      "Epoch    7/1000 | Train Loss: 0.6607 | Val Loss: 0.6630 | Best Val: 0.6538\n",
      "Epoch    8/1000 | Train Loss: 0.6396 | Val Loss: 0.6707 | Best Val: 0.6538\n",
      "Epoch    9/1000 | Train Loss: 0.6316 | Val Loss: 0.6688 | Best Val: 0.6538\n",
      "Epoch   10/1000 | Train Loss: 0.6281 | Val Loss: 0.6652 | Best Val: 0.6538\n",
      "Epoch   11/1000 | Train Loss: 0.6161 | Val Loss: 0.6691 | Best Val: 0.6538\n",
      "Epoch   12/1000 | Train Loss: 0.6126 | Val Loss: 0.6701 | Best Val: 0.6538\n",
      "Epoch   13/1000 | Train Loss: 0.6103 | Val Loss: 0.6701 | Best Val: 0.6538\n",
      "Epoch   14/1000 | Train Loss: 0.6079 | Val Loss: 0.6711 | Best Val: 0.6538\n",
      "Epoch   15/1000 | Train Loss: 0.6063 | Val Loss: 0.6705 | Best Val: 0.6538\n",
      "Epoch   16/1000 | Train Loss: 0.6048 | Val Loss: 0.6706 | Best Val: 0.6538\n",
      "Early stopping triggered at epoch 16\n",
      "\n",
      "Fold 2/12\n",
      "Epoch    1/1000 | Train Loss: 0.6557 | Val Loss: 0.7049 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6302 | Val Loss: 0.6998 | Best Val: 0.7049\n",
      "Epoch    3/1000 | Train Loss: 0.6140 | Val Loss: 0.7105 | Best Val: 0.6998\n",
      "Epoch    4/1000 | Train Loss: 0.6078 | Val Loss: 0.7166 | Best Val: 0.6998\n",
      "Epoch    5/1000 | Train Loss: 0.6087 | Val Loss: 0.7491 | Best Val: 0.6998\n",
      "Epoch    6/1000 | Train Loss: 0.5973 | Val Loss: 0.7243 | Best Val: 0.6998\n",
      "Epoch    7/1000 | Train Loss: 0.5921 | Val Loss: 0.7435 | Best Val: 0.6998\n",
      "Epoch    8/1000 | Train Loss: 0.5878 | Val Loss: 0.7335 | Best Val: 0.6998\n",
      "Epoch    9/1000 | Train Loss: 0.5945 | Val Loss: 0.7593 | Best Val: 0.6998\n",
      "Epoch   10/1000 | Train Loss: 0.5846 | Val Loss: 0.7256 | Best Val: 0.6998\n",
      "Epoch   11/1000 | Train Loss: 0.5820 | Val Loss: 0.7311 | Best Val: 0.6998\n",
      "Epoch   12/1000 | Train Loss: 0.5775 | Val Loss: 0.7354 | Best Val: 0.6998\n",
      "Early stopping triggered at epoch 12\n",
      "\n",
      "Fold 3/12\n",
      "Epoch    1/1000 | Train Loss: 0.6447 | Val Loss: 0.8412 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6094 | Val Loss: 0.8184 | Best Val: 0.8412\n",
      "Epoch    3/1000 | Train Loss: 0.6016 | Val Loss: 0.7902 | Best Val: 0.8184\n",
      "Epoch    4/1000 | Train Loss: 0.5916 | Val Loss: 0.7876 | Best Val: 0.7902\n",
      "Epoch    5/1000 | Train Loss: 0.5890 | Val Loss: 0.7661 | Best Val: 0.7876\n",
      "Epoch    6/1000 | Train Loss: 0.5809 | Val Loss: 0.7790 | Best Val: 0.7661\n",
      "Epoch    7/1000 | Train Loss: 0.5876 | Val Loss: 0.7661 | Best Val: 0.7661\n",
      "Epoch    8/1000 | Train Loss: 0.5810 | Val Loss: 0.8366 | Best Val: 0.7661\n",
      "Epoch    9/1000 | Train Loss: 0.5827 | Val Loss: 0.8204 | Best Val: 0.7661\n",
      "Epoch   10/1000 | Train Loss: 0.5788 | Val Loss: 0.8525 | Best Val: 0.7661\n",
      "Epoch   11/1000 | Train Loss: 0.5671 | Val Loss: 0.8410 | Best Val: 0.7661\n",
      "Epoch   12/1000 | Train Loss: 0.5619 | Val Loss: 0.8312 | Best Val: 0.7661\n",
      "Epoch   13/1000 | Train Loss: 0.5591 | Val Loss: 0.8265 | Best Val: 0.7661\n",
      "Epoch   14/1000 | Train Loss: 0.5573 | Val Loss: 0.8245 | Best Val: 0.7661\n",
      "Epoch   15/1000 | Train Loss: 0.5566 | Val Loss: 0.8211 | Best Val: 0.7661\n",
      "Epoch   16/1000 | Train Loss: 0.5554 | Val Loss: 0.8229 | Best Val: 0.7661\n",
      "Epoch   17/1000 | Train Loss: 0.5552 | Val Loss: 0.8251 | Best Val: 0.7661\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Fold 4/12\n",
      "Epoch    1/1000 | Train Loss: 0.6110 | Val Loss: 0.6915 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.5956 | Val Loss: 0.6765 | Best Val: 0.6915\n",
      "Epoch    3/1000 | Train Loss: 0.5883 | Val Loss: 0.6741 | Best Val: 0.6765\n",
      "Epoch    4/1000 | Train Loss: 0.5800 | Val Loss: 0.6830 | Best Val: 0.6741\n",
      "Epoch    5/1000 | Train Loss: 0.5735 | Val Loss: 0.6467 | Best Val: 0.6741\n",
      "Epoch    6/1000 | Train Loss: 0.5703 | Val Loss: 0.6643 | Best Val: 0.6467\n",
      "Epoch    7/1000 | Train Loss: 0.5670 | Val Loss: 0.6399 | Best Val: 0.6467\n",
      "Epoch    8/1000 | Train Loss: 0.5621 | Val Loss: 0.6406 | Best Val: 0.6399\n",
      "Epoch    9/1000 | Train Loss: 0.5605 | Val Loss: 0.6569 | Best Val: 0.6399\n",
      "Epoch   10/1000 | Train Loss: 0.5670 | Val Loss: 0.6430 | Best Val: 0.6399\n",
      "Epoch   11/1000 | Train Loss: 0.5583 | Val Loss: 0.6398 | Best Val: 0.6399\n",
      "Epoch   12/1000 | Train Loss: 0.5526 | Val Loss: 0.6399 | Best Val: 0.6398\n",
      "Epoch   13/1000 | Train Loss: 0.5486 | Val Loss: 0.6403 | Best Val: 0.6398\n",
      "Epoch   14/1000 | Train Loss: 0.5459 | Val Loss: 0.6415 | Best Val: 0.6398\n",
      "Epoch   15/1000 | Train Loss: 0.5439 | Val Loss: 0.6423 | Best Val: 0.6398\n",
      "Epoch   16/1000 | Train Loss: 0.5420 | Val Loss: 0.6429 | Best Val: 0.6398\n",
      "Epoch   17/1000 | Train Loss: 0.5410 | Val Loss: 0.6440 | Best Val: 0.6398\n",
      "Epoch   18/1000 | Train Loss: 0.5400 | Val Loss: 0.6440 | Best Val: 0.6398\n",
      "Epoch   19/1000 | Train Loss: 0.5388 | Val Loss: 0.6425 | Best Val: 0.6398\n",
      "Epoch   20/1000 | Train Loss: 0.5380 | Val Loss: 0.6436 | Best Val: 0.6398\n",
      "Epoch   21/1000 | Train Loss: 0.5369 | Val Loss: 0.6433 | Best Val: 0.6398\n",
      "Early stopping triggered at epoch 21\n",
      "\n",
      "Fold 5/12\n",
      "Epoch    1/1000 | Train Loss: 0.6615 | Val Loss: 0.7522 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6147 | Val Loss: 0.7674 | Best Val: 0.7522\n",
      "Epoch    3/1000 | Train Loss: 0.6032 | Val Loss: 0.7832 | Best Val: 0.7522\n",
      "Epoch    4/1000 | Train Loss: 0.5891 | Val Loss: 0.7751 | Best Val: 0.7522\n",
      "Epoch    5/1000 | Train Loss: 0.5784 | Val Loss: 0.7757 | Best Val: 0.7522\n",
      "Epoch    6/1000 | Train Loss: 0.5638 | Val Loss: 0.7761 | Best Val: 0.7522\n",
      "Epoch    7/1000 | Train Loss: 0.5658 | Val Loss: 0.7807 | Best Val: 0.7522\n",
      "Epoch    8/1000 | Train Loss: 0.5601 | Val Loss: 0.7510 | Best Val: 0.7522\n",
      "Epoch    9/1000 | Train Loss: 0.5645 | Val Loss: 0.7704 | Best Val: 0.7510\n",
      "Epoch   10/1000 | Train Loss: 0.5565 | Val Loss: 0.7698 | Best Val: 0.7510\n",
      "Epoch   11/1000 | Train Loss: 0.5487 | Val Loss: 0.7638 | Best Val: 0.7510\n",
      "Epoch   12/1000 | Train Loss: 0.5433 | Val Loss: 0.7669 | Best Val: 0.7510\n",
      "Epoch   13/1000 | Train Loss: 0.5407 | Val Loss: 0.7664 | Best Val: 0.7510\n",
      "Epoch   14/1000 | Train Loss: 0.5395 | Val Loss: 0.7680 | Best Val: 0.7510\n",
      "Epoch   15/1000 | Train Loss: 0.5379 | Val Loss: 0.7665 | Best Val: 0.7510\n",
      "Epoch   16/1000 | Train Loss: 0.5370 | Val Loss: 0.7674 | Best Val: 0.7510\n",
      "Epoch   17/1000 | Train Loss: 0.5365 | Val Loss: 0.7648 | Best Val: 0.7510\n",
      "Epoch   18/1000 | Train Loss: 0.5354 | Val Loss: 0.7644 | Best Val: 0.7510\n",
      "Early stopping triggered at epoch 18\n",
      "\n",
      "Fold 6/12\n",
      "Epoch    1/1000 | Train Loss: 0.6449 | Val Loss: 0.7261 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6123 | Val Loss: 0.7178 | Best Val: 0.7261\n",
      "Epoch    3/1000 | Train Loss: 0.5838 | Val Loss: 0.7149 | Best Val: 0.7178\n",
      "Epoch    4/1000 | Train Loss: 0.5899 | Val Loss: 0.7109 | Best Val: 0.7149\n",
      "Epoch    5/1000 | Train Loss: 0.5861 | Val Loss: 0.7313 | Best Val: 0.7109\n",
      "Epoch    6/1000 | Train Loss: 0.5889 | Val Loss: 0.7535 | Best Val: 0.7109\n",
      "Epoch    7/1000 | Train Loss: 0.5801 | Val Loss: 0.7446 | Best Val: 0.7109\n",
      "Epoch    8/1000 | Train Loss: 0.5650 | Val Loss: 0.7634 | Best Val: 0.7109\n",
      "Epoch    9/1000 | Train Loss: 0.5687 | Val Loss: 0.7422 | Best Val: 0.7109\n",
      "Epoch   10/1000 | Train Loss: 0.5547 | Val Loss: 0.7353 | Best Val: 0.7109\n",
      "Epoch   11/1000 | Train Loss: 0.5545 | Val Loss: 0.7397 | Best Val: 0.7109\n",
      "Epoch   12/1000 | Train Loss: 0.5481 | Val Loss: 0.7411 | Best Val: 0.7109\n",
      "Epoch   13/1000 | Train Loss: 0.5455 | Val Loss: 0.7416 | Best Val: 0.7109\n",
      "Epoch   14/1000 | Train Loss: 0.5438 | Val Loss: 0.7387 | Best Val: 0.7109\n",
      "Early stopping triggered at epoch 14\n",
      "\n",
      "Fold 7/12\n",
      "Epoch    1/1000 | Train Loss: 0.6988 | Val Loss: 0.6890 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6358 | Val Loss: 0.6664 | Best Val: 0.6890\n",
      "Epoch    3/1000 | Train Loss: 0.6136 | Val Loss: 0.6305 | Best Val: 0.6664\n",
      "Epoch    4/1000 | Train Loss: 0.5935 | Val Loss: 0.6201 | Best Val: 0.6305\n",
      "Epoch    5/1000 | Train Loss: 0.6090 | Val Loss: 0.6253 | Best Val: 0.6201\n",
      "Epoch    6/1000 | Train Loss: 0.5826 | Val Loss: 0.6148 | Best Val: 0.6201\n",
      "Epoch    7/1000 | Train Loss: 0.5820 | Val Loss: 0.5970 | Best Val: 0.6148\n",
      "Epoch    8/1000 | Train Loss: 0.5759 | Val Loss: 0.6035 | Best Val: 0.5970\n",
      "Epoch    9/1000 | Train Loss: 0.5813 | Val Loss: 0.5851 | Best Val: 0.5970\n",
      "Epoch   10/1000 | Train Loss: 0.5654 | Val Loss: 0.5811 | Best Val: 0.5851\n",
      "Epoch   11/1000 | Train Loss: 0.5582 | Val Loss: 0.5756 | Best Val: 0.5811\n",
      "Epoch   12/1000 | Train Loss: 0.5546 | Val Loss: 0.5747 | Best Val: 0.5756\n",
      "Epoch   13/1000 | Train Loss: 0.5519 | Val Loss: 0.5748 | Best Val: 0.5747\n",
      "Epoch   14/1000 | Train Loss: 0.5499 | Val Loss: 0.5750 | Best Val: 0.5747\n",
      "Epoch   15/1000 | Train Loss: 0.5484 | Val Loss: 0.5754 | Best Val: 0.5747\n",
      "Epoch   16/1000 | Train Loss: 0.5470 | Val Loss: 0.5759 | Best Val: 0.5747\n",
      "Epoch   17/1000 | Train Loss: 0.5458 | Val Loss: 0.5765 | Best Val: 0.5747\n",
      "Epoch   18/1000 | Train Loss: 0.5450 | Val Loss: 0.5757 | Best Val: 0.5747\n",
      "Epoch   19/1000 | Train Loss: 0.5438 | Val Loss: 0.5751 | Best Val: 0.5747\n",
      "Epoch   20/1000 | Train Loss: 0.5432 | Val Loss: 0.5749 | Best Val: 0.5747\n",
      "Epoch   21/1000 | Train Loss: 0.5420 | Val Loss: 0.5748 | Best Val: 0.5747\n",
      "Epoch   22/1000 | Train Loss: 0.5419 | Val Loss: 0.5749 | Best Val: 0.5747\n",
      "Early stopping triggered at epoch 22\n",
      "\n",
      "Fold 8/12\n",
      "Epoch    1/1000 | Train Loss: 0.6469 | Val Loss: 0.7114 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6042 | Val Loss: 0.7323 | Best Val: 0.7114\n",
      "Epoch    3/1000 | Train Loss: 0.5846 | Val Loss: 0.7297 | Best Val: 0.7114\n",
      "Epoch    4/1000 | Train Loss: 0.5909 | Val Loss: 0.7293 | Best Val: 0.7114\n",
      "Epoch    5/1000 | Train Loss: 0.5797 | Val Loss: 0.7271 | Best Val: 0.7114\n",
      "Epoch    6/1000 | Train Loss: 0.5696 | Val Loss: 0.7169 | Best Val: 0.7114\n",
      "Epoch    7/1000 | Train Loss: 0.5629 | Val Loss: 0.7227 | Best Val: 0.7114\n",
      "Epoch    8/1000 | Train Loss: 0.5654 | Val Loss: 0.7309 | Best Val: 0.7114\n",
      "Epoch    9/1000 | Train Loss: 0.5695 | Val Loss: 0.7621 | Best Val: 0.7114\n",
      "Epoch   10/1000 | Train Loss: 0.5618 | Val Loss: 0.7278 | Best Val: 0.7114\n",
      "Epoch   11/1000 | Train Loss: 0.5548 | Val Loss: 0.7253 | Best Val: 0.7114\n",
      "Early stopping triggered at epoch 11\n",
      "\n",
      "Fold 9/12\n",
      "Epoch    1/1000 | Train Loss: 0.6669 | Val Loss: 0.8198 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6201 | Val Loss: 0.7888 | Best Val: 0.8198\n",
      "Epoch    3/1000 | Train Loss: 0.5977 | Val Loss: 0.7775 | Best Val: 0.7888\n",
      "Epoch    4/1000 | Train Loss: 0.5885 | Val Loss: 0.7828 | Best Val: 0.7775\n",
      "Epoch    5/1000 | Train Loss: 0.5817 | Val Loss: 0.7978 | Best Val: 0.7775\n",
      "Epoch    6/1000 | Train Loss: 0.5778 | Val Loss: 0.7634 | Best Val: 0.7775\n",
      "Epoch    7/1000 | Train Loss: 0.5679 | Val Loss: 0.8113 | Best Val: 0.7634\n",
      "Epoch    8/1000 | Train Loss: 0.5705 | Val Loss: 0.7679 | Best Val: 0.7634\n",
      "Epoch    9/1000 | Train Loss: 0.5647 | Val Loss: 0.7813 | Best Val: 0.7634\n",
      "Epoch   10/1000 | Train Loss: 0.5675 | Val Loss: 0.7617 | Best Val: 0.7634\n",
      "Epoch   11/1000 | Train Loss: 0.5607 | Val Loss: 0.7610 | Best Val: 0.7617\n",
      "Epoch   12/1000 | Train Loss: 0.5545 | Val Loss: 0.7610 | Best Val: 0.7610\n",
      "Epoch   13/1000 | Train Loss: 0.5501 | Val Loss: 0.7627 | Best Val: 0.7610\n",
      "Epoch   14/1000 | Train Loss: 0.5482 | Val Loss: 0.7662 | Best Val: 0.7610\n",
      "Epoch   15/1000 | Train Loss: 0.5457 | Val Loss: 0.7672 | Best Val: 0.7610\n",
      "Epoch   16/1000 | Train Loss: 0.5444 | Val Loss: 0.7680 | Best Val: 0.7610\n",
      "Epoch   17/1000 | Train Loss: 0.5430 | Val Loss: 0.7671 | Best Val: 0.7610\n",
      "Epoch   18/1000 | Train Loss: 0.5423 | Val Loss: 0.7667 | Best Val: 0.7610\n",
      "Epoch   19/1000 | Train Loss: 0.5411 | Val Loss: 0.7688 | Best Val: 0.7610\n",
      "Epoch   20/1000 | Train Loss: 0.5405 | Val Loss: 0.7665 | Best Val: 0.7610\n",
      "Epoch   21/1000 | Train Loss: 0.5397 | Val Loss: 0.7667 | Best Val: 0.7610\n",
      "Early stopping triggered at epoch 21\n",
      "\n",
      "Fold 10/12\n",
      "Epoch    1/1000 | Train Loss: 0.6316 | Val Loss: 0.6803 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.5839 | Val Loss: 0.6722 | Best Val: 0.6803\n",
      "Epoch    3/1000 | Train Loss: 0.5712 | Val Loss: 0.6622 | Best Val: 0.6722\n",
      "Epoch    4/1000 | Train Loss: 0.5633 | Val Loss: 0.6886 | Best Val: 0.6622\n",
      "Epoch    5/1000 | Train Loss: 0.5652 | Val Loss: 0.6811 | Best Val: 0.6622\n",
      "Epoch    6/1000 | Train Loss: 0.5491 | Val Loss: 0.6709 | Best Val: 0.6622\n",
      "Epoch    7/1000 | Train Loss: 0.5681 | Val Loss: 0.6500 | Best Val: 0.6622\n",
      "Epoch    8/1000 | Train Loss: 0.5496 | Val Loss: 0.6580 | Best Val: 0.6500\n",
      "Epoch    9/1000 | Train Loss: 0.5668 | Val Loss: 0.6643 | Best Val: 0.6500\n",
      "Epoch   10/1000 | Train Loss: 0.5409 | Val Loss: 0.6619 | Best Val: 0.6500\n",
      "Epoch   11/1000 | Train Loss: 0.5321 | Val Loss: 0.6664 | Best Val: 0.6500\n",
      "Epoch   12/1000 | Train Loss: 0.5286 | Val Loss: 0.6675 | Best Val: 0.6500\n",
      "Epoch   13/1000 | Train Loss: 0.5262 | Val Loss: 0.6676 | Best Val: 0.6500\n",
      "Epoch   14/1000 | Train Loss: 0.5271 | Val Loss: 0.6673 | Best Val: 0.6500\n",
      "Epoch   15/1000 | Train Loss: 0.5284 | Val Loss: 0.6676 | Best Val: 0.6500\n",
      "Epoch   16/1000 | Train Loss: 0.5280 | Val Loss: 0.6681 | Best Val: 0.6500\n",
      "Epoch   17/1000 | Train Loss: 0.5271 | Val Loss: 0.6674 | Best Val: 0.6500\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Fold 11/12\n",
      "Epoch    1/1000 | Train Loss: 0.6366 | Val Loss: 0.6389 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6078 | Val Loss: 0.6657 | Best Val: 0.6389\n",
      "Epoch    3/1000 | Train Loss: 0.5938 | Val Loss: 0.6715 | Best Val: 0.6389\n",
      "Epoch    4/1000 | Train Loss: 0.6058 | Val Loss: 0.6775 | Best Val: 0.6389\n",
      "Epoch    5/1000 | Train Loss: 0.5825 | Val Loss: 0.7023 | Best Val: 0.6389\n",
      "Epoch    6/1000 | Train Loss: 0.5700 | Val Loss: 0.6941 | Best Val: 0.6389\n",
      "Epoch    7/1000 | Train Loss: 0.5749 | Val Loss: 0.7172 | Best Val: 0.6389\n",
      "Epoch    8/1000 | Train Loss: 0.5781 | Val Loss: 0.7420 | Best Val: 0.6389\n",
      "Epoch    9/1000 | Train Loss: 0.5750 | Val Loss: 0.7134 | Best Val: 0.6389\n",
      "Epoch   10/1000 | Train Loss: 0.5638 | Val Loss: 0.7000 | Best Val: 0.6389\n",
      "Epoch   11/1000 | Train Loss: 0.5522 | Val Loss: 0.7038 | Best Val: 0.6389\n",
      "Early stopping triggered at epoch 11\n",
      "\n",
      "Fold 12/12\n",
      "Epoch    1/1000 | Train Loss: 0.6332 | Val Loss: 0.6341 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6094 | Val Loss: 0.6432 | Best Val: 0.6341\n",
      "Epoch    3/1000 | Train Loss: 0.5873 | Val Loss: 0.6497 | Best Val: 0.6341\n",
      "Epoch    4/1000 | Train Loss: 0.5779 | Val Loss: 0.6428 | Best Val: 0.6341\n",
      "Epoch    5/1000 | Train Loss: 0.5725 | Val Loss: 0.6706 | Best Val: 0.6341\n",
      "Epoch    6/1000 | Train Loss: 0.5764 | Val Loss: 0.6633 | Best Val: 0.6341\n",
      "Epoch    7/1000 | Train Loss: 0.5669 | Val Loss: 0.6758 | Best Val: 0.6341\n",
      "Epoch    8/1000 | Train Loss: 0.5650 | Val Loss: 0.6933 | Best Val: 0.6341\n",
      "Epoch    9/1000 | Train Loss: 0.5771 | Val Loss: 0.6536 | Best Val: 0.6341\n",
      "Epoch   10/1000 | Train Loss: 0.5729 | Val Loss: 0.6731 | Best Val: 0.6341\n",
      "Epoch   11/1000 | Train Loss: 0.5791 | Val Loss: 0.6790 | Best Val: 0.6341\n",
      "Early stopping triggered at epoch 11\n"
     ]
    }
   ],
   "source": [
    "result = train_kfold(\n",
    "    model=model,\n",
    "    roundness=data[\"ExperimentalRoundScore\"],\n",
    "    texts=data[\"Stimuli\"],\n",
    "    batch_size=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=1000,\n",
    "    patience=10,\n",
    "    k=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7830832 , 0.27874008], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34154534, 0.30129448], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/roundness_determiner_v03.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(\n",
    "    model=model,\n",
    "    directory=f\"outputs/\",\n",
    "    filename=f\"roundness_determiner_v0{VERSION}.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from outputs/roundness_determiner_v03.pth\n"
     ]
    }
   ],
   "source": [
    "model = load_model(directory=\"outputs/\", filename=f\"roundness_determiner_v0{VERSION}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78308326, 0.27874017], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34154546, 0.30129448], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kineratote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rutsusajibo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poutano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uyoshipasu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>gechigapaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ragi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>mugugo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>rureto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>miramaupi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pseudoword\n",
       "0      kineratote\n",
       "1     rutsusajibo\n",
       "2            neza\n",
       "3         poutano\n",
       "4      uyoshipasu\n",
       "...           ...\n",
       "9995  gechigapaba\n",
       "9996         ragi\n",
       "9997       mugugo\n",
       "9998       rureto\n",
       "9999    miramaupi\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = json.load(open(\"datasets/words.json\"))\n",
    "\n",
    "# Function to generate a random string from data\n",
    "def generate_random_string(data, min_len=2, max_len=5):\n",
    "    length = random.randint(min_len, max_len)\n",
    "    return ''.join(random.choices(list(data.keys()), k=length))\n",
    "\n",
    "# Generate 5000 unique strings\n",
    "unique_strings = set()\n",
    "while len(unique_strings) < 10000:\n",
    "    unique_strings.add(generate_random_string(data))\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame(list(unique_strings), columns=['Pseudoword'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kineratote</td>\n",
       "      <td>0.150207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rutsusajibo</td>\n",
       "      <td>0.110635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neza</td>\n",
       "      <td>0.468633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poutano</td>\n",
       "      <td>0.326936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uyoshipasu</td>\n",
       "      <td>0.131503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>gechigapaba</td>\n",
       "      <td>0.077712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ragi</td>\n",
       "      <td>0.351221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>mugugo</td>\n",
       "      <td>0.234996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>rureto</td>\n",
       "      <td>0.280292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>miramaupi</td>\n",
       "      <td>0.089597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pseudoword  Roundness\n",
       "0      kineratote   0.150207\n",
       "1     rutsusajibo   0.110635\n",
       "2            neza   0.468633\n",
       "3         poutano   0.326936\n",
       "4      uyoshipasu   0.131503\n",
       "...           ...        ...\n",
       "9995  gechigapaba   0.077712\n",
       "9996         ragi   0.351221\n",
       "9997       mugugo   0.234996\n",
       "9998       rureto   0.280292\n",
       "9999    miramaupi   0.089597\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Roundness\"] = model.inference(data[\"Pseudoword\"].to_list())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.259523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.196518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.038889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.090111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.248405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.345424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.860149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Roundness\n",
       "count  10000.000000\n",
       "mean       0.259523\n",
       "std        0.196518\n",
       "min        0.038889\n",
       "25%        0.090111\n",
       "50%        0.248405\n",
       "75%        0.345424\n",
       "max        0.860149"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"datasets/japanese_pseudowords.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudoword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
