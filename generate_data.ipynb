{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to generate more data for the main model to use.\n",
    "\n",
    "This model is trained on (normalized.csv) to be able to predict the roundness of pseudowords.\n",
    "\n",
    "This is because the original dataset (normalized.csv) only contains 124 rows, and it is insufficient to train a large model like the ByT5-Pseudword-Generator. Hence, this model should learn to predict the roundness values of pseudowords, then be applied on a larger dataset to create a dataset of pseudoword-roundness pairs that will be used to train the ByT5-Pseudword-Generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.roundness_determiner import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "\n",
    "\n",
    "state = 42\n",
    "VERSION = \"3.0\"\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stimuli</th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bebi</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibe</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bobou</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boubo</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chechi</td>\n",
       "      <td>0.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>outou</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>uku</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ulu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>umu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>utu</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stimuli  ExperimentalRoundScore\n",
       "0      bebi                0.815217\n",
       "1      bibe                0.913043\n",
       "2     bobou                0.815217\n",
       "3     boubo                1.000000\n",
       "4    chechi                0.184783\n",
       "..      ...                     ...\n",
       "119   outou                0.347826\n",
       "120     uku                0.239130\n",
       "121     ulu                0.913043\n",
       "122     umu                0.913043\n",
       "123     utu                0.239130\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/normalized.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.316366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ExperimentalRoundScore\n",
       "count              124.000000\n",
       "mean                 0.562675\n",
       "std                  0.316366\n",
       "min                  0.000000\n",
       "25%                  0.260870\n",
       "50%                  0.543478\n",
       "75%                  0.902174\n",
       "max                  1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RoundnessDeterminerBERT(\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    hidden_size=768,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/12\n",
      "Epoch    1/1000 | Train Loss: 1.0953 | Val Loss: 1.6349 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.9071 | Val Loss: 0.8919 | Best Val: 1.6349\n",
      "Epoch    3/1000 | Train Loss: 0.7870 | Val Loss: 0.7759 | Best Val: 0.8919\n",
      "Epoch    4/1000 | Train Loss: 0.7191 | Val Loss: 0.6989 | Best Val: 0.7759\n",
      "Epoch    5/1000 | Train Loss: 0.7261 | Val Loss: 0.7823 | Best Val: 0.6989\n",
      "Epoch    6/1000 | Train Loss: 0.7145 | Val Loss: 0.7057 | Best Val: 0.6989\n",
      "Epoch    7/1000 | Train Loss: 0.7210 | Val Loss: 0.6833 | Best Val: 0.6989\n",
      "Epoch    8/1000 | Train Loss: 0.6800 | Val Loss: 0.6917 | Best Val: 0.6833\n",
      "Epoch    9/1000 | Train Loss: 0.7253 | Val Loss: 0.6881 | Best Val: 0.6833\n",
      "Epoch   10/1000 | Train Loss: 0.6760 | Val Loss: 0.7470 | Best Val: 0.6833\n",
      "Epoch   11/1000 | Train Loss: 0.6845 | Val Loss: 0.7406 | Best Val: 0.6833\n",
      "Epoch   12/1000 | Train Loss: 0.6848 | Val Loss: 0.7151 | Best Val: 0.6833\n",
      "Epoch   13/1000 | Train Loss: 0.6339 | Val Loss: 0.6898 | Best Val: 0.6833\n",
      "Epoch   14/1000 | Train Loss: 0.6517 | Val Loss: 0.7030 | Best Val: 0.6833\n",
      "Epoch   15/1000 | Train Loss: 0.6408 | Val Loss: 0.7052 | Best Val: 0.6833\n",
      "Epoch   16/1000 | Train Loss: 0.6323 | Val Loss: 0.7085 | Best Val: 0.6833\n",
      "Epoch   17/1000 | Train Loss: 0.6647 | Val Loss: 0.7040 | Best Val: 0.6833\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Fold 2/12\n",
      "Epoch    1/1000 | Train Loss: 0.7199 | Val Loss: 0.6636 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6796 | Val Loss: 0.6015 | Best Val: 0.6636\n",
      "Epoch    3/1000 | Train Loss: 0.6688 | Val Loss: 0.6278 | Best Val: 0.6015\n",
      "Epoch    4/1000 | Train Loss: 0.6897 | Val Loss: 0.6527 | Best Val: 0.6015\n",
      "Epoch    5/1000 | Train Loss: 0.6950 | Val Loss: 0.6043 | Best Val: 0.6015\n",
      "Epoch    6/1000 | Train Loss: 0.6846 | Val Loss: 0.6204 | Best Val: 0.6015\n",
      "Epoch    7/1000 | Train Loss: 0.7000 | Val Loss: 0.6216 | Best Val: 0.6015\n",
      "Epoch    8/1000 | Train Loss: 0.6866 | Val Loss: 0.6412 | Best Val: 0.6015\n",
      "Epoch    9/1000 | Train Loss: 0.6757 | Val Loss: 0.5813 | Best Val: 0.6015\n",
      "Epoch   10/1000 | Train Loss: 0.6771 | Val Loss: 0.5686 | Best Val: 0.5813\n",
      "Epoch   11/1000 | Train Loss: 0.6415 | Val Loss: 0.5669 | Best Val: 0.5686\n",
      "Epoch   12/1000 | Train Loss: 0.6318 | Val Loss: 0.5647 | Best Val: 0.5669\n",
      "Epoch   13/1000 | Train Loss: 0.6518 | Val Loss: 0.5773 | Best Val: 0.5647\n",
      "Epoch   14/1000 | Train Loss: 0.6396 | Val Loss: 0.5706 | Best Val: 0.5647\n",
      "Epoch   15/1000 | Train Loss: 0.6546 | Val Loss: 0.5810 | Best Val: 0.5647\n",
      "Epoch   16/1000 | Train Loss: 0.6479 | Val Loss: 0.5944 | Best Val: 0.5647\n",
      "Epoch   17/1000 | Train Loss: 0.6439 | Val Loss: 0.5942 | Best Val: 0.5647\n",
      "Epoch   18/1000 | Train Loss: 0.6362 | Val Loss: 0.5984 | Best Val: 0.5647\n",
      "Epoch   19/1000 | Train Loss: 0.6266 | Val Loss: 0.6050 | Best Val: 0.5647\n",
      "Epoch   20/1000 | Train Loss: 0.6330 | Val Loss: 0.5975 | Best Val: 0.5647\n",
      "Epoch   21/1000 | Train Loss: 0.6272 | Val Loss: 0.5907 | Best Val: 0.5647\n",
      "Epoch   22/1000 | Train Loss: 0.6384 | Val Loss: 0.5973 | Best Val: 0.5647\n",
      "Early stopping triggered at epoch 22\n",
      "\n",
      "Fold 3/12\n",
      "Epoch    1/1000 | Train Loss: 0.7042 | Val Loss: 0.6201 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6996 | Val Loss: 0.6273 | Best Val: 0.6201\n",
      "Epoch    3/1000 | Train Loss: 0.6718 | Val Loss: 0.6190 | Best Val: 0.6201\n",
      "Epoch    4/1000 | Train Loss: 0.6845 | Val Loss: 0.6457 | Best Val: 0.6190\n",
      "Epoch    5/1000 | Train Loss: 0.6904 | Val Loss: 0.6240 | Best Val: 0.6190\n",
      "Epoch    6/1000 | Train Loss: 0.6577 | Val Loss: 0.6147 | Best Val: 0.6190\n",
      "Epoch    7/1000 | Train Loss: 0.6715 | Val Loss: 0.6849 | Best Val: 0.6147\n",
      "Epoch    8/1000 | Train Loss: 0.6739 | Val Loss: 0.6136 | Best Val: 0.6147\n",
      "Epoch    9/1000 | Train Loss: 0.6717 | Val Loss: 0.6244 | Best Val: 0.6136\n",
      "Epoch   10/1000 | Train Loss: 0.6627 | Val Loss: 0.6300 | Best Val: 0.6136\n",
      "Epoch   11/1000 | Train Loss: 0.6390 | Val Loss: 0.6117 | Best Val: 0.6136\n",
      "Epoch   12/1000 | Train Loss: 0.6279 | Val Loss: 0.6214 | Best Val: 0.6117\n",
      "Epoch   13/1000 | Train Loss: 0.6182 | Val Loss: 0.6171 | Best Val: 0.6117\n",
      "Epoch   14/1000 | Train Loss: 0.6131 | Val Loss: 0.6031 | Best Val: 0.6117\n",
      "Epoch   15/1000 | Train Loss: 0.6360 | Val Loss: 0.5989 | Best Val: 0.6031\n",
      "Epoch   16/1000 | Train Loss: 0.6363 | Val Loss: 0.6251 | Best Val: 0.5989\n",
      "Epoch   17/1000 | Train Loss: 0.6346 | Val Loss: 0.6093 | Best Val: 0.5989\n",
      "Epoch   18/1000 | Train Loss: 0.6414 | Val Loss: 0.6020 | Best Val: 0.5989\n",
      "Epoch   19/1000 | Train Loss: 0.6299 | Val Loss: 0.6099 | Best Val: 0.5989\n",
      "Epoch   20/1000 | Train Loss: 0.6332 | Val Loss: 0.5966 | Best Val: 0.5989\n",
      "Epoch   21/1000 | Train Loss: 0.6240 | Val Loss: 0.6078 | Best Val: 0.5966\n",
      "Epoch   22/1000 | Train Loss: 0.6321 | Val Loss: 0.6046 | Best Val: 0.5966\n",
      "Epoch   23/1000 | Train Loss: 0.6378 | Val Loss: 0.6007 | Best Val: 0.5966\n",
      "Epoch   24/1000 | Train Loss: 0.6100 | Val Loss: 0.5977 | Best Val: 0.5966\n",
      "Epoch   25/1000 | Train Loss: 0.6081 | Val Loss: 0.6084 | Best Val: 0.5966\n",
      "Epoch   26/1000 | Train Loss: 0.6383 | Val Loss: 0.6036 | Best Val: 0.5966\n",
      "Epoch   27/1000 | Train Loss: 0.6586 | Val Loss: 0.6115 | Best Val: 0.5966\n",
      "Epoch   28/1000 | Train Loss: 0.6435 | Val Loss: 0.5995 | Best Val: 0.5966\n",
      "Epoch   29/1000 | Train Loss: 0.6367 | Val Loss: 0.6021 | Best Val: 0.5966\n",
      "Epoch   30/1000 | Train Loss: 0.6375 | Val Loss: 0.6031 | Best Val: 0.5966\n",
      "Early stopping triggered at epoch 30\n",
      "\n",
      "Fold 4/12\n",
      "Epoch    1/1000 | Train Loss: 0.6532 | Val Loss: 0.5840 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6785 | Val Loss: 0.5433 | Best Val: 0.5840\n",
      "Epoch    3/1000 | Train Loss: 0.6639 | Val Loss: 0.5906 | Best Val: 0.5433\n",
      "Epoch    4/1000 | Train Loss: 0.6685 | Val Loss: 0.5653 | Best Val: 0.5433\n",
      "Epoch    5/1000 | Train Loss: 0.6543 | Val Loss: 0.5525 | Best Val: 0.5433\n",
      "Epoch    6/1000 | Train Loss: 0.6462 | Val Loss: 0.5578 | Best Val: 0.5433\n",
      "Epoch    7/1000 | Train Loss: 0.6322 | Val Loss: 0.5394 | Best Val: 0.5433\n",
      "Epoch    8/1000 | Train Loss: 0.6286 | Val Loss: 0.5037 | Best Val: 0.5394\n",
      "Epoch    9/1000 | Train Loss: 0.6543 | Val Loss: 0.5067 | Best Val: 0.5037\n",
      "Epoch   10/1000 | Train Loss: 0.6384 | Val Loss: 0.5605 | Best Val: 0.5037\n",
      "Epoch   11/1000 | Train Loss: 0.6195 | Val Loss: 0.5583 | Best Val: 0.5037\n",
      "Epoch   12/1000 | Train Loss: 0.6484 | Val Loss: 0.5736 | Best Val: 0.5037\n",
      "Epoch   13/1000 | Train Loss: 0.6361 | Val Loss: 0.5547 | Best Val: 0.5037\n",
      "Epoch   14/1000 | Train Loss: 0.6129 | Val Loss: 0.5599 | Best Val: 0.5037\n",
      "Epoch   15/1000 | Train Loss: 0.6032 | Val Loss: 0.5505 | Best Val: 0.5037\n",
      "Epoch   16/1000 | Train Loss: 0.6198 | Val Loss: 0.5415 | Best Val: 0.5037\n",
      "Epoch   17/1000 | Train Loss: 0.6192 | Val Loss: 0.5477 | Best Val: 0.5037\n",
      "Epoch   18/1000 | Train Loss: 0.6240 | Val Loss: 0.5502 | Best Val: 0.5037\n",
      "Early stopping triggered at epoch 18\n",
      "\n",
      "Fold 5/12\n",
      "Epoch    1/1000 | Train Loss: 0.6547 | Val Loss: 0.5937 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6728 | Val Loss: 0.5613 | Best Val: 0.5937\n",
      "Epoch    3/1000 | Train Loss: 0.6285 | Val Loss: 0.5388 | Best Val: 0.5613\n",
      "Epoch    4/1000 | Train Loss: 0.6686 | Val Loss: 0.5233 | Best Val: 0.5388\n",
      "Epoch    5/1000 | Train Loss: 0.6740 | Val Loss: 0.5475 | Best Val: 0.5233\n",
      "Epoch    6/1000 | Train Loss: 0.6647 | Val Loss: 0.5734 | Best Val: 0.5233\n",
      "Epoch    7/1000 | Train Loss: 0.6534 | Val Loss: 0.5453 | Best Val: 0.5233\n",
      "Epoch    8/1000 | Train Loss: 0.6620 | Val Loss: 0.5621 | Best Val: 0.5233\n",
      "Epoch    9/1000 | Train Loss: 0.6388 | Val Loss: 0.5335 | Best Val: 0.5233\n",
      "Epoch   10/1000 | Train Loss: 0.6500 | Val Loss: 0.5945 | Best Val: 0.5233\n",
      "Epoch   11/1000 | Train Loss: 0.6329 | Val Loss: 0.5747 | Best Val: 0.5233\n",
      "Epoch   12/1000 | Train Loss: 0.6278 | Val Loss: 0.5668 | Best Val: 0.5233\n",
      "Epoch   13/1000 | Train Loss: 0.6031 | Val Loss: 0.5269 | Best Val: 0.5233\n",
      "Epoch   14/1000 | Train Loss: 0.6201 | Val Loss: 0.5256 | Best Val: 0.5233\n",
      "Early stopping triggered at epoch 14\n",
      "\n",
      "Fold 6/12\n",
      "Epoch    1/1000 | Train Loss: 0.6396 | Val Loss: 0.6165 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6480 | Val Loss: 0.5665 | Best Val: 0.6165\n",
      "Epoch    3/1000 | Train Loss: 0.6252 | Val Loss: 0.5228 | Best Val: 0.5665\n",
      "Epoch    4/1000 | Train Loss: 0.6285 | Val Loss: 0.5639 | Best Val: 0.5228\n",
      "Epoch    5/1000 | Train Loss: 0.6247 | Val Loss: 0.5846 | Best Val: 0.5228\n",
      "Epoch    6/1000 | Train Loss: 0.6327 | Val Loss: 0.5747 | Best Val: 0.5228\n",
      "Epoch    7/1000 | Train Loss: 0.6509 | Val Loss: 0.5922 | Best Val: 0.5228\n",
      "Epoch    8/1000 | Train Loss: 0.6362 | Val Loss: 0.5504 | Best Val: 0.5228\n",
      "Epoch    9/1000 | Train Loss: 0.6303 | Val Loss: 0.5856 | Best Val: 0.5228\n",
      "Epoch   10/1000 | Train Loss: 0.6151 | Val Loss: 0.5949 | Best Val: 0.5228\n",
      "Epoch   11/1000 | Train Loss: 0.6118 | Val Loss: 0.5696 | Best Val: 0.5228\n",
      "Epoch   12/1000 | Train Loss: 0.6199 | Val Loss: 0.5682 | Best Val: 0.5228\n",
      "Epoch   13/1000 | Train Loss: 0.6172 | Val Loss: 0.5710 | Best Val: 0.5228\n",
      "Early stopping triggered at epoch 13\n",
      "\n",
      "Fold 7/12\n",
      "Epoch    1/1000 | Train Loss: 0.6697 | Val Loss: 0.4445 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6645 | Val Loss: 0.5361 | Best Val: 0.4445\n",
      "Epoch    3/1000 | Train Loss: 0.6405 | Val Loss: 0.4719 | Best Val: 0.4445\n",
      "Epoch    4/1000 | Train Loss: 0.6445 | Val Loss: 0.5591 | Best Val: 0.4445\n",
      "Epoch    5/1000 | Train Loss: 0.6676 | Val Loss: 0.5614 | Best Val: 0.4445\n",
      "Epoch    6/1000 | Train Loss: 0.6453 | Val Loss: 0.5161 | Best Val: 0.4445\n",
      "Epoch    7/1000 | Train Loss: 0.6557 | Val Loss: 0.5408 | Best Val: 0.4445\n",
      "Epoch    8/1000 | Train Loss: 0.6305 | Val Loss: 0.5210 | Best Val: 0.4445\n",
      "Epoch    9/1000 | Train Loss: 0.6505 | Val Loss: 0.5265 | Best Val: 0.4445\n",
      "Epoch   10/1000 | Train Loss: 0.6399 | Val Loss: 0.5434 | Best Val: 0.4445\n",
      "Epoch   11/1000 | Train Loss: 0.6348 | Val Loss: 0.5173 | Best Val: 0.4445\n",
      "Early stopping triggered at epoch 11\n",
      "\n",
      "Fold 8/12\n",
      "Epoch    1/1000 | Train Loss: 0.7046 | Val Loss: 0.6740 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6552 | Val Loss: 0.6431 | Best Val: 0.6740\n",
      "Epoch    3/1000 | Train Loss: 0.6478 | Val Loss: 0.6357 | Best Val: 0.6431\n",
      "Epoch    4/1000 | Train Loss: 0.6274 | Val Loss: 0.6446 | Best Val: 0.6357\n",
      "Epoch    5/1000 | Train Loss: 0.6477 | Val Loss: 0.6479 | Best Val: 0.6357\n",
      "Epoch    6/1000 | Train Loss: 0.6378 | Val Loss: 0.6367 | Best Val: 0.6357\n",
      "Epoch    7/1000 | Train Loss: 0.6427 | Val Loss: 0.6268 | Best Val: 0.6357\n",
      "Epoch    8/1000 | Train Loss: 0.6539 | Val Loss: 0.6173 | Best Val: 0.6268\n",
      "Epoch    9/1000 | Train Loss: 0.6378 | Val Loss: 0.6121 | Best Val: 0.6173\n",
      "Epoch   10/1000 | Train Loss: 0.6171 | Val Loss: 0.6335 | Best Val: 0.6121\n",
      "Epoch   11/1000 | Train Loss: 0.6368 | Val Loss: 0.6515 | Best Val: 0.6121\n",
      "Epoch   12/1000 | Train Loss: 0.6038 | Val Loss: 0.6415 | Best Val: 0.6121\n",
      "Epoch   13/1000 | Train Loss: 0.6474 | Val Loss: 0.6322 | Best Val: 0.6121\n",
      "Epoch   14/1000 | Train Loss: 0.6002 | Val Loss: 0.6388 | Best Val: 0.6121\n",
      "Epoch   15/1000 | Train Loss: 0.6193 | Val Loss: 0.6403 | Best Val: 0.6121\n",
      "Epoch   16/1000 | Train Loss: 0.6264 | Val Loss: 0.6299 | Best Val: 0.6121\n",
      "Epoch   17/1000 | Train Loss: 0.6158 | Val Loss: 0.6449 | Best Val: 0.6121\n",
      "Epoch   18/1000 | Train Loss: 0.6088 | Val Loss: 0.6524 | Best Val: 0.6121\n",
      "Epoch   19/1000 | Train Loss: 0.6134 | Val Loss: 0.6518 | Best Val: 0.6121\n",
      "Early stopping triggered at epoch 19\n",
      "\n",
      "Fold 9/12\n",
      "Epoch    1/1000 | Train Loss: 0.6565 | Val Loss: 0.6518 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6113 | Val Loss: 0.6156 | Best Val: 0.6518\n",
      "Epoch    3/1000 | Train Loss: 0.6172 | Val Loss: 0.6247 | Best Val: 0.6156\n",
      "Epoch    4/1000 | Train Loss: 0.6289 | Val Loss: 0.6289 | Best Val: 0.6156\n",
      "Epoch    5/1000 | Train Loss: 0.6246 | Val Loss: 0.6266 | Best Val: 0.6156\n",
      "Epoch    6/1000 | Train Loss: 0.6425 | Val Loss: 0.6700 | Best Val: 0.6156\n",
      "Epoch    7/1000 | Train Loss: 0.6090 | Val Loss: 0.6521 | Best Val: 0.6156\n",
      "Epoch    8/1000 | Train Loss: 0.6210 | Val Loss: 0.6443 | Best Val: 0.6156\n",
      "Epoch    9/1000 | Train Loss: 0.6019 | Val Loss: 0.6125 | Best Val: 0.6156\n",
      "Epoch   10/1000 | Train Loss: 0.6273 | Val Loss: 0.6274 | Best Val: 0.6125\n",
      "Epoch   11/1000 | Train Loss: 0.6015 | Val Loss: 0.6168 | Best Val: 0.6125\n",
      "Epoch   12/1000 | Train Loss: 0.6181 | Val Loss: 0.5925 | Best Val: 0.6125\n",
      "Epoch   13/1000 | Train Loss: 0.6021 | Val Loss: 0.5976 | Best Val: 0.5925\n",
      "Epoch   14/1000 | Train Loss: 0.6056 | Val Loss: 0.5969 | Best Val: 0.5925\n",
      "Epoch   15/1000 | Train Loss: 0.5927 | Val Loss: 0.6095 | Best Val: 0.5925\n",
      "Epoch   16/1000 | Train Loss: 0.6067 | Val Loss: 0.5855 | Best Val: 0.5925\n",
      "Epoch   17/1000 | Train Loss: 0.6132 | Val Loss: 0.6129 | Best Val: 0.5855\n",
      "Epoch   18/1000 | Train Loss: 0.5873 | Val Loss: 0.5970 | Best Val: 0.5855\n",
      "Epoch   19/1000 | Train Loss: 0.5896 | Val Loss: 0.5956 | Best Val: 0.5855\n",
      "Epoch   20/1000 | Train Loss: 0.5862 | Val Loss: 0.6098 | Best Val: 0.5855\n",
      "Epoch   21/1000 | Train Loss: 0.6076 | Val Loss: 0.6092 | Best Val: 0.5855\n",
      "Epoch   22/1000 | Train Loss: 0.5978 | Val Loss: 0.6086 | Best Val: 0.5855\n",
      "Epoch   23/1000 | Train Loss: 0.6030 | Val Loss: 0.5964 | Best Val: 0.5855\n",
      "Epoch   24/1000 | Train Loss: 0.5967 | Val Loss: 0.5931 | Best Val: 0.5855\n",
      "Epoch   25/1000 | Train Loss: 0.5983 | Val Loss: 0.5972 | Best Val: 0.5855\n",
      "Epoch   26/1000 | Train Loss: 0.5808 | Val Loss: 0.5987 | Best Val: 0.5855\n",
      "Early stopping triggered at epoch 26\n",
      "\n",
      "Fold 10/12\n",
      "Epoch    1/1000 | Train Loss: 0.6342 | Val Loss: 0.5150 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6206 | Val Loss: 0.5320 | Best Val: 0.5150\n",
      "Epoch    3/1000 | Train Loss: 0.6229 | Val Loss: 0.5371 | Best Val: 0.5150\n",
      "Epoch    4/1000 | Train Loss: 0.6207 | Val Loss: 0.5472 | Best Val: 0.5150\n",
      "Epoch    5/1000 | Train Loss: 0.6148 | Val Loss: 0.5863 | Best Val: 0.5150\n",
      "Epoch    6/1000 | Train Loss: 0.6026 | Val Loss: 0.5526 | Best Val: 0.5150\n",
      "Epoch    7/1000 | Train Loss: 0.6074 | Val Loss: 0.5716 | Best Val: 0.5150\n",
      "Epoch    8/1000 | Train Loss: 0.6344 | Val Loss: 0.5904 | Best Val: 0.5150\n",
      "Epoch    9/1000 | Train Loss: 0.6259 | Val Loss: 0.5201 | Best Val: 0.5150\n",
      "Epoch   10/1000 | Train Loss: 0.6059 | Val Loss: 0.5183 | Best Val: 0.5150\n",
      "Epoch   11/1000 | Train Loss: 0.5800 | Val Loss: 0.5321 | Best Val: 0.5150\n",
      "Early stopping triggered at epoch 11\n",
      "\n",
      "Fold 11/12\n",
      "Epoch    1/1000 | Train Loss: 0.6602 | Val Loss: 0.5974 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6228 | Val Loss: 0.5782 | Best Val: 0.5974\n",
      "Epoch    3/1000 | Train Loss: 0.6308 | Val Loss: 0.5685 | Best Val: 0.5782\n",
      "Epoch    4/1000 | Train Loss: 0.6445 | Val Loss: 0.6064 | Best Val: 0.5685\n",
      "Epoch    5/1000 | Train Loss: 0.6295 | Val Loss: 0.6090 | Best Val: 0.5685\n",
      "Epoch    6/1000 | Train Loss: 0.6188 | Val Loss: 0.6135 | Best Val: 0.5685\n",
      "Epoch    7/1000 | Train Loss: 0.6290 | Val Loss: 0.5652 | Best Val: 0.5685\n",
      "Epoch    8/1000 | Train Loss: 0.6197 | Val Loss: 0.6015 | Best Val: 0.5652\n",
      "Epoch    9/1000 | Train Loss: 0.6312 | Val Loss: 0.5893 | Best Val: 0.5652\n",
      "Epoch   10/1000 | Train Loss: 0.6170 | Val Loss: 0.5994 | Best Val: 0.5652\n",
      "Epoch   11/1000 | Train Loss: 0.6035 | Val Loss: 0.6016 | Best Val: 0.5652\n",
      "Epoch   12/1000 | Train Loss: 0.6072 | Val Loss: 0.6086 | Best Val: 0.5652\n",
      "Epoch   13/1000 | Train Loss: 0.6003 | Val Loss: 0.6148 | Best Val: 0.5652\n",
      "Epoch   14/1000 | Train Loss: 0.6178 | Val Loss: 0.5826 | Best Val: 0.5652\n",
      "Epoch   15/1000 | Train Loss: 0.6176 | Val Loss: 0.6028 | Best Val: 0.5652\n",
      "Epoch   16/1000 | Train Loss: 0.6130 | Val Loss: 0.5957 | Best Val: 0.5652\n",
      "Epoch   17/1000 | Train Loss: 0.6021 | Val Loss: 0.6154 | Best Val: 0.5652\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Fold 12/12\n",
      "Epoch    1/1000 | Train Loss: 0.6495 | Val Loss: 0.5977 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6270 | Val Loss: 0.6159 | Best Val: 0.5977\n",
      "Epoch    3/1000 | Train Loss: 0.6330 | Val Loss: 0.6044 | Best Val: 0.5977\n",
      "Epoch    4/1000 | Train Loss: 0.6265 | Val Loss: 0.5994 | Best Val: 0.5977\n",
      "Epoch    5/1000 | Train Loss: 0.6280 | Val Loss: 0.6216 | Best Val: 0.5977\n",
      "Epoch    6/1000 | Train Loss: 0.6351 | Val Loss: 0.6173 | Best Val: 0.5977\n",
      "Epoch    7/1000 | Train Loss: 0.6255 | Val Loss: 0.6167 | Best Val: 0.5977\n",
      "Epoch    8/1000 | Train Loss: 0.6189 | Val Loss: 0.6047 | Best Val: 0.5977\n",
      "Epoch    9/1000 | Train Loss: 0.6072 | Val Loss: 0.6259 | Best Val: 0.5977\n",
      "Epoch   10/1000 | Train Loss: 0.6142 | Val Loss: 0.6271 | Best Val: 0.5977\n",
      "Epoch   11/1000 | Train Loss: 0.5974 | Val Loss: 0.6234 | Best Val: 0.5977\n",
      "Early stopping triggered at epoch 11\n"
     ]
    }
   ],
   "source": [
    "result = train_kfold(\n",
    "    model=model,\n",
    "    roundness=data[\"ExperimentalRoundScore\"],\n",
    "    texts=data[\"Stimuli\"],\n",
    "    batch_size=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=1000,\n",
    "    patience=10,\n",
    "    k=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43793532, 0.2597781 ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5786823 , 0.28268924], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/roundness_determiner_v03.1.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(\n",
    "    model=model,\n",
    "    directory=f\"outputs/\",\n",
    "    filename=f\"roundness_determiner_v0{VERSION}.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from outputs/roundness_determiner_v03.1.pth\n"
     ]
    }
   ],
   "source": [
    "model = load_model(directory=\"outputs/\", filename=f\"roundness_determiner_v0{VERSION}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43793482, 0.25977808], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5786822 , 0.28268903], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irepeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tsupihamumo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tademunoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tsujidenubo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>musa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>sateihemu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pekene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pseudoword\n",
       "0          irepeo\n",
       "1             bea\n",
       "2            kiko\n",
       "3     tsupihamumo\n",
       "4            koke\n",
       "...           ...\n",
       "9995    tademunoo\n",
       "9996  tsujidenubo\n",
       "9997         musa\n",
       "9998    sateihemu\n",
       "9999       pekene\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = json.load(open(\"datasets/words.json\"))\n",
    "\n",
    "# Function to generate a random string from data\n",
    "def generate_random_string(data, min_len=2, max_len=5):\n",
    "    length = random.randint(min_len, max_len)\n",
    "    return ''.join(random.choices(list(data.keys()), k=length))\n",
    "\n",
    "# Generate 5000 unique strings\n",
    "unique_strings = set()\n",
    "while len(unique_strings) < 10000:\n",
    "    unique_strings.add(generate_random_string(data))\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame(list(unique_strings), columns=['Pseudoword'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irepeo</td>\n",
       "      <td>0.481853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bea</td>\n",
       "      <td>0.562284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiko</td>\n",
       "      <td>0.371239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tsupihamumo</td>\n",
       "      <td>0.235215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koke</td>\n",
       "      <td>0.212681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>tademunoo</td>\n",
       "      <td>0.782395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>tsujidenubo</td>\n",
       "      <td>0.339519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>musa</td>\n",
       "      <td>0.517813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>sateihemu</td>\n",
       "      <td>0.492698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pekene</td>\n",
       "      <td>0.458165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pseudoword  Roundness\n",
       "0          irepeo   0.481853\n",
       "1             bea   0.562284\n",
       "2            kiko   0.371239\n",
       "3     tsupihamumo   0.235215\n",
       "4            koke   0.212681\n",
       "...           ...        ...\n",
       "9995    tademunoo   0.782395\n",
       "9996  tsujidenubo   0.339519\n",
       "9997         musa   0.517813\n",
       "9998    sateihemu   0.492698\n",
       "9999       pekene   0.458165\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Roundness\"] = model.inference(data[\"Pseudoword\"].to_list())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.169169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.172221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.372915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.494394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.613484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.891836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Roundness\n",
       "count  10000.000000\n",
       "mean       0.500261\n",
       "std        0.169169\n",
       "min        0.172221\n",
       "25%        0.372915\n",
       "50%        0.494394\n",
       "75%        0.613484\n",
       "max        0.891836"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"datasets/japanese_pseudowords.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudoword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
