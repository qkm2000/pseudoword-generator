{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to generate more data for the main model to use.\n",
    "\n",
    "This model is trained on (normalized.csv) to be able to predict the roundness of pseudowords.\n",
    "\n",
    "This is because the original dataset (normalized.csv) only contains 124 rows, and it is insufficient to train a large model like the ByT5-Pseudword-Generator. Hence, this model should learn to predict the roundness values of pseudowords, then be applied on a larger dataset to create a dataset of pseudoword-roundness pairs that will be used to train the ByT5-Pseudword-Generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.roundness_determiner import *\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "state = 42\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "random.seed(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stimuli</th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bebi</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bibe</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bobou</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boubo</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chechi</td>\n",
       "      <td>0.184783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>outou</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>uku</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ulu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>umu</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>utu</td>\n",
       "      <td>0.239130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stimuli  ExperimentalRoundScore\n",
       "0      bebi                0.815217\n",
       "1      bibe                0.913043\n",
       "2     bobou                0.815217\n",
       "3     boubo                1.000000\n",
       "4    chechi                0.184783\n",
       "..      ...                     ...\n",
       "119   outou                0.347826\n",
       "120     uku                0.239130\n",
       "121     ulu                0.913043\n",
       "122     umu                0.913043\n",
       "123     utu                0.239130\n",
       "\n",
       "[124 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/normalized.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExperimentalRoundScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.316366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ExperimentalRoundScore\n",
       "count              124.000000\n",
       "mean                 0.562675\n",
       "std                  0.316366\n",
       "min                  0.000000\n",
       "25%                  0.260870\n",
       "50%                  0.543478\n",
       "75%                  0.902174\n",
       "max                  1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RoundnessDeterminerBERT(\n",
    "    model_name=model_name,\n",
    "    hidden_size=768,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/4\n",
      "Epoch    1/1000 | Train Loss: 0.9733 | Val Loss: 0.7455 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.8597 | Val Loss: 0.6643 | Best Val: 0.7455\n",
      "Epoch    3/1000 | Train Loss: 0.7101 | Val Loss: 0.7195 | Best Val: 0.6643\n",
      "Epoch    4/1000 | Train Loss: 0.7231 | Val Loss: 0.7014 | Best Val: 0.6643\n",
      "Epoch    5/1000 | Train Loss: 0.7172 | Val Loss: 0.6583 | Best Val: 0.6643\n",
      "Epoch    6/1000 | Train Loss: 0.6886 | Val Loss: 0.6519 | Best Val: 0.6583\n",
      "Epoch    7/1000 | Train Loss: 0.6872 | Val Loss: 0.6614 | Best Val: 0.6519\n",
      "Epoch    8/1000 | Train Loss: 0.6970 | Val Loss: 0.6643 | Best Val: 0.6519\n",
      "Epoch    9/1000 | Train Loss: 0.6847 | Val Loss: 0.7220 | Best Val: 0.6519\n",
      "Epoch   10/1000 | Train Loss: 0.7255 | Val Loss: 0.6556 | Best Val: 0.6519\n",
      "Epoch   11/1000 | Train Loss: 0.6830 | Val Loss: 0.6645 | Best Val: 0.6519\n",
      "Epoch   12/1000 | Train Loss: 0.6571 | Val Loss: 0.6606 | Best Val: 0.6519\n",
      "Epoch   13/1000 | Train Loss: 0.6683 | Val Loss: 0.6521 | Best Val: 0.6519\n",
      "Epoch   14/1000 | Train Loss: 0.6695 | Val Loss: 0.6411 | Best Val: 0.6519\n",
      "Epoch   15/1000 | Train Loss: 0.6636 | Val Loss: 0.6495 | Best Val: 0.6411\n",
      "Epoch   16/1000 | Train Loss: 0.6649 | Val Loss: 0.6488 | Best Val: 0.6411\n",
      "Epoch   17/1000 | Train Loss: 0.6482 | Val Loss: 0.6366 | Best Val: 0.6411\n",
      "Epoch   18/1000 | Train Loss: 0.6607 | Val Loss: 0.6362 | Best Val: 0.6366\n",
      "Epoch   19/1000 | Train Loss: 0.6864 | Val Loss: 0.6416 | Best Val: 0.6362\n",
      "Epoch   20/1000 | Train Loss: 0.6650 | Val Loss: 0.6369 | Best Val: 0.6362\n",
      "Epoch   21/1000 | Train Loss: 0.6599 | Val Loss: 0.6318 | Best Val: 0.6362\n",
      "Epoch   22/1000 | Train Loss: 0.6546 | Val Loss: 0.6360 | Best Val: 0.6318\n",
      "Epoch   23/1000 | Train Loss: 0.6510 | Val Loss: 0.6410 | Best Val: 0.6318\n",
      "Epoch   24/1000 | Train Loss: 0.6660 | Val Loss: 0.6400 | Best Val: 0.6318\n",
      "Epoch   25/1000 | Train Loss: 0.6706 | Val Loss: 0.6385 | Best Val: 0.6318\n",
      "Epoch   26/1000 | Train Loss: 0.6618 | Val Loss: 0.6389 | Best Val: 0.6318\n",
      "Epoch   27/1000 | Train Loss: 0.6567 | Val Loss: 0.6454 | Best Val: 0.6318\n",
      "Epoch   28/1000 | Train Loss: 0.6665 | Val Loss: 0.6442 | Best Val: 0.6318\n",
      "Epoch   29/1000 | Train Loss: 0.6518 | Val Loss: 0.6426 | Best Val: 0.6318\n",
      "Epoch   30/1000 | Train Loss: 0.6417 | Val Loss: 0.6393 | Best Val: 0.6318\n",
      "Epoch   31/1000 | Train Loss: 0.6381 | Val Loss: 0.6464 | Best Val: 0.6318\n",
      "Early stopping triggered at epoch 31\n",
      "\n",
      "Fold 2/4\n",
      "Epoch    1/1000 | Train Loss: 0.7220 | Val Loss: 0.6322 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.7296 | Val Loss: 0.6567 | Best Val: 0.6322\n",
      "Epoch    3/1000 | Train Loss: 0.6969 | Val Loss: 0.7457 | Best Val: 0.6322\n",
      "Epoch    4/1000 | Train Loss: 0.6870 | Val Loss: 0.6164 | Best Val: 0.6322\n",
      "Epoch    5/1000 | Train Loss: 0.7414 | Val Loss: 0.6273 | Best Val: 0.6164\n",
      "Epoch    6/1000 | Train Loss: 0.6836 | Val Loss: 0.6348 | Best Val: 0.6164\n",
      "Epoch    7/1000 | Train Loss: 0.6709 | Val Loss: 0.6586 | Best Val: 0.6164\n",
      "Epoch    8/1000 | Train Loss: 0.6978 | Val Loss: 0.6296 | Best Val: 0.6164\n",
      "Epoch    9/1000 | Train Loss: 0.6761 | Val Loss: 0.6582 | Best Val: 0.6164\n",
      "Epoch   10/1000 | Train Loss: 0.6769 | Val Loss: 0.6178 | Best Val: 0.6164\n",
      "Epoch   11/1000 | Train Loss: 0.6582 | Val Loss: 0.6302 | Best Val: 0.6164\n",
      "Epoch   12/1000 | Train Loss: 0.6533 | Val Loss: 0.6210 | Best Val: 0.6164\n",
      "Epoch   13/1000 | Train Loss: 0.6750 | Val Loss: 0.6140 | Best Val: 0.6164\n",
      "Epoch   14/1000 | Train Loss: 0.6682 | Val Loss: 0.6204 | Best Val: 0.6140\n",
      "Epoch   15/1000 | Train Loss: 0.6612 | Val Loss: 0.6187 | Best Val: 0.6140\n",
      "Epoch   16/1000 | Train Loss: 0.6558 | Val Loss: 0.6274 | Best Val: 0.6140\n",
      "Epoch   17/1000 | Train Loss: 0.6259 | Val Loss: 0.6094 | Best Val: 0.6140\n",
      "Epoch   18/1000 | Train Loss: 0.6458 | Val Loss: 0.6128 | Best Val: 0.6094\n",
      "Epoch   19/1000 | Train Loss: 0.6480 | Val Loss: 0.6024 | Best Val: 0.6094\n",
      "Epoch   20/1000 | Train Loss: 0.6593 | Val Loss: 0.5861 | Best Val: 0.6024\n",
      "Epoch   21/1000 | Train Loss: 0.6376 | Val Loss: 0.6051 | Best Val: 0.5861\n",
      "Epoch   22/1000 | Train Loss: 0.6540 | Val Loss: 0.5876 | Best Val: 0.5861\n",
      "Epoch   23/1000 | Train Loss: 0.6458 | Val Loss: 0.5958 | Best Val: 0.5861\n",
      "Epoch   24/1000 | Train Loss: 0.6353 | Val Loss: 0.5903 | Best Val: 0.5861\n",
      "Epoch   25/1000 | Train Loss: 0.6639 | Val Loss: 0.5989 | Best Val: 0.5861\n",
      "Epoch   26/1000 | Train Loss: 0.6328 | Val Loss: 0.5951 | Best Val: 0.5861\n",
      "Epoch   27/1000 | Train Loss: 0.6229 | Val Loss: 0.5823 | Best Val: 0.5861\n",
      "Epoch   28/1000 | Train Loss: 0.6198 | Val Loss: 0.5960 | Best Val: 0.5823\n",
      "Epoch   29/1000 | Train Loss: 0.6647 | Val Loss: 0.5909 | Best Val: 0.5823\n",
      "Epoch   30/1000 | Train Loss: 0.6478 | Val Loss: 0.5943 | Best Val: 0.5823\n",
      "Epoch   31/1000 | Train Loss: 0.6393 | Val Loss: 0.6026 | Best Val: 0.5823\n",
      "Epoch   32/1000 | Train Loss: 0.6682 | Val Loss: 0.5990 | Best Val: 0.5823\n",
      "Epoch   33/1000 | Train Loss: 0.6315 | Val Loss: 0.5965 | Best Val: 0.5823\n",
      "Epoch   34/1000 | Train Loss: 0.6404 | Val Loss: 0.6053 | Best Val: 0.5823\n",
      "Epoch   35/1000 | Train Loss: 0.6427 | Val Loss: 0.5990 | Best Val: 0.5823\n",
      "Epoch   36/1000 | Train Loss: 0.6157 | Val Loss: 0.5969 | Best Val: 0.5823\n",
      "Epoch   37/1000 | Train Loss: 0.6386 | Val Loss: 0.5922 | Best Val: 0.5823\n",
      "Early stopping triggered at epoch 37\n",
      "\n",
      "Fold 3/4\n",
      "Epoch    1/1000 | Train Loss: 0.6693 | Val Loss: 0.7123 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.7067 | Val Loss: 0.6622 | Best Val: 0.7123\n",
      "Epoch    3/1000 | Train Loss: 0.7028 | Val Loss: 0.6543 | Best Val: 0.6622\n",
      "Epoch    4/1000 | Train Loss: 0.6609 | Val Loss: 0.6675 | Best Val: 0.6543\n",
      "Epoch    5/1000 | Train Loss: 0.6741 | Val Loss: 0.7104 | Best Val: 0.6543\n",
      "Epoch    6/1000 | Train Loss: 0.6692 | Val Loss: 0.6492 | Best Val: 0.6543\n",
      "Epoch    7/1000 | Train Loss: 0.6540 | Val Loss: 0.6436 | Best Val: 0.6492\n",
      "Epoch    8/1000 | Train Loss: 0.6736 | Val Loss: 0.6440 | Best Val: 0.6436\n",
      "Epoch    9/1000 | Train Loss: 0.6830 | Val Loss: 0.6623 | Best Val: 0.6436\n",
      "Epoch   10/1000 | Train Loss: 0.6444 | Val Loss: 0.6555 | Best Val: 0.6436\n",
      "Epoch   11/1000 | Train Loss: 0.6802 | Val Loss: 0.6473 | Best Val: 0.6436\n",
      "Epoch   12/1000 | Train Loss: 0.6388 | Val Loss: 0.6463 | Best Val: 0.6436\n",
      "Epoch   13/1000 | Train Loss: 0.6502 | Val Loss: 0.6463 | Best Val: 0.6436\n",
      "Epoch   14/1000 | Train Loss: 0.6399 | Val Loss: 0.6492 | Best Val: 0.6436\n",
      "Epoch   15/1000 | Train Loss: 0.6371 | Val Loss: 0.6562 | Best Val: 0.6436\n",
      "Epoch   16/1000 | Train Loss: 0.6414 | Val Loss: 0.6498 | Best Val: 0.6436\n",
      "Epoch   17/1000 | Train Loss: 0.6363 | Val Loss: 0.6480 | Best Val: 0.6436\n",
      "Early stopping triggered at epoch 17\n",
      "\n",
      "Fold 4/4\n",
      "Epoch    1/1000 | Train Loss: 0.6963 | Val Loss: 0.6784 | Best Val: inf\n",
      "Epoch    2/1000 | Train Loss: 0.6647 | Val Loss: 0.6441 | Best Val: 0.6784\n",
      "Epoch    3/1000 | Train Loss: 0.6983 | Val Loss: 0.6838 | Best Val: 0.6441\n",
      "Epoch    4/1000 | Train Loss: 0.6919 | Val Loss: 0.6558 | Best Val: 0.6441\n",
      "Epoch    5/1000 | Train Loss: 0.6745 | Val Loss: 0.6508 | Best Val: 0.6441\n",
      "Epoch    6/1000 | Train Loss: 0.6478 | Val Loss: 0.6609 | Best Val: 0.6441\n",
      "Epoch    7/1000 | Train Loss: 0.6625 | Val Loss: 0.7254 | Best Val: 0.6441\n",
      "Epoch    8/1000 | Train Loss: 0.6393 | Val Loss: 0.7001 | Best Val: 0.6441\n",
      "Epoch    9/1000 | Train Loss: 0.6636 | Val Loss: 0.6324 | Best Val: 0.6441\n",
      "Epoch   10/1000 | Train Loss: 0.6547 | Val Loss: 0.6534 | Best Val: 0.6324\n",
      "Epoch   11/1000 | Train Loss: 0.6502 | Val Loss: 0.6475 | Best Val: 0.6324\n",
      "Epoch   12/1000 | Train Loss: 0.6491 | Val Loss: 0.6590 | Best Val: 0.6324\n",
      "Epoch   13/1000 | Train Loss: 0.6603 | Val Loss: 0.6426 | Best Val: 0.6324\n",
      "Epoch   14/1000 | Train Loss: 0.6395 | Val Loss: 0.6504 | Best Val: 0.6324\n",
      "Epoch   15/1000 | Train Loss: 0.6453 | Val Loss: 0.6441 | Best Val: 0.6324\n",
      "Epoch   16/1000 | Train Loss: 0.6325 | Val Loss: 0.6415 | Best Val: 0.6324\n",
      "Epoch   17/1000 | Train Loss: 0.6704 | Val Loss: 0.6508 | Best Val: 0.6324\n",
      "Epoch   18/1000 | Train Loss: 0.6303 | Val Loss: 0.6451 | Best Val: 0.6324\n",
      "Epoch   19/1000 | Train Loss: 0.6291 | Val Loss: 0.6402 | Best Val: 0.6324\n",
      "Early stopping triggered at epoch 19\n"
     ]
    }
   ],
   "source": [
    "result = train_kfold(\n",
    "    model=model,\n",
    "    roundness=data[\"ExperimentalRoundScore\"],\n",
    "    texts=data[\"Stimuli\"],\n",
    "    batch_size=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=1000,\n",
    "    patience=10,\n",
    "    k=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6258093 , 0.42961788], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58911127, 0.4978615 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to outputs/roundness_determiner_v03.1.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(\n",
    "    model=model,\n",
    "    directory=f\"outputs/\",\n",
    "    filename=f\"roundness_determiner_v0{os.getenv(\"VERSION\")}.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from outputs/roundness_determiner_v03.1.pth\n"
     ]
    }
   ],
   "source": [
    "model = load_model(directory=\"outputs/\", filename=f\"roundness_determiner_v0{os.getenv('VERSION')}.pth\", model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6258093 , 0.42961788], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"bouba\", \"kiki\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58911127, 0.4978615 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = [\"maluma\", \"takete\"]\n",
    "model.inference(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mepako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nushi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poipaau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>hipupasago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>poniga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>pubo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>dadapa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>nse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pseudoword\n",
       "0         mepako\n",
       "1           bayo\n",
       "2           depe\n",
       "3          nushi\n",
       "4        poipaau\n",
       "...          ...\n",
       "9995  hipupasago\n",
       "9996      poniga\n",
       "9997        pubo\n",
       "9998      dadapa\n",
       "9999         nse\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "data = json.load(open(\"datasets/words.json\"))\n",
    "\n",
    "# Function to generate a random string from data\n",
    "def generate_random_string(data, min_len=2, max_len=5):\n",
    "    length = random.randint(min_len, max_len)\n",
    "    return ''.join(random.choices(list(data.keys()), k=length))\n",
    "\n",
    "# Generate 5000 unique strings\n",
    "unique_strings = set()\n",
    "while len(unique_strings) < 10000:\n",
    "    unique_strings.add(generate_random_string(data))\n",
    "\n",
    "# Convert to DataFrame\n",
    "data = pd.DataFrame(list(unique_strings), columns=['Pseudoword'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pseudoword</th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mepako</td>\n",
       "      <td>0.529904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayo</td>\n",
       "      <td>0.572885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depe</td>\n",
       "      <td>0.505724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nushi</td>\n",
       "      <td>0.588515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poipaau</td>\n",
       "      <td>0.527272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>hipupasago</td>\n",
       "      <td>0.574199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>poniga</td>\n",
       "      <td>0.544438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>pubo</td>\n",
       "      <td>0.555564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>dadapa</td>\n",
       "      <td>0.567358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>nse</td>\n",
       "      <td>0.550246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pseudoword  Roundness\n",
       "0         mepako   0.529904\n",
       "1           bayo   0.572885\n",
       "2           depe   0.505724\n",
       "3          nushi   0.588515\n",
       "4        poipaau   0.527272\n",
       "...          ...        ...\n",
       "9995  hipupasago   0.574199\n",
       "9996      poniga   0.544438\n",
       "9997        pubo   0.555564\n",
       "9998      dadapa   0.567358\n",
       "9999         nse   0.550246\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Roundness\"] = model.inference(data[\"Pseudoword\"].to_list())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Roundness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.043833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.388763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.571022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.701714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Roundness\n",
       "count  10000.000000\n",
       "mean       0.541609\n",
       "std        0.043833\n",
       "min        0.388763\n",
       "25%        0.510010\n",
       "50%        0.540788\n",
       "75%        0.571022\n",
       "max        0.701714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f\"datasets/japanese_pseudowords_{os.getenv(\"VERSION\")}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudoword",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
